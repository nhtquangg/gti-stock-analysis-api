# Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
try:
    from vnstock import Vnstock
    print("ƒê√£ import th√†nh c√¥ng th∆∞ vi·ªán vnstock")
except ImportError:
    print("Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán vnstock. Vui l√≤ng ch·∫°y: pip install vnstock")
    import sys
    sys.exit(1)

try:
    import ta
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    print("ƒê√£ import th√†nh c√¥ng th∆∞ vi·ªán ta, pandas, numpy v√† datetime")
except ImportError:
    print("Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán ta, pandas ho·∫∑c numpy. Vui l√≤ng ch·∫°y: pip install ta pandas numpy")
    import sys
    sys.exit(1)

import concurrent.futures
import time
from config import GTIConfig
from rate_limiter import rate_limited_call, rate_limiter

def lay_du_lieu_co_phieu_vnstock(ma_co_phieu: str, start_date: str = "2023-01-01", end_date: str = "2024-12-31"):
    """
    H√†m n√†y l·∫•y d·ªØ li·ªáu gi√° l·ªãch s·ª≠ c·ªßa m·ªôt m√£ c·ªï phi·∫øu s·ª≠ d·ª•ng th∆∞ vi·ªán vnstock 3.x.
    üõ°Ô∏è PROTECTED BY RATE LIMITER
    
    Args:
        ma_co_phieu (str): M√£ ch·ª©ng kho√°n c·∫ßn l·∫•y, v√≠ d·ª•: "FPT", "HPG".
        start_date (str): Ng√†y b·∫Øt ƒë·∫ßu, ƒë·ªãnh d·∫°ng YYYY-MM-DD
        end_date (str): Ng√†y k·∫øt th√∫c, ƒë·ªãnh d·∫°ng YYYY-MM-DD

    Returns:
        DataFrame ch·ª©a d·ªØ li·ªáu l·ªãch s·ª≠ n·∫øu th√†nh c√¥ng, ho·∫∑c None n·∫øu c√≥ l·ªói.
    """
    print(f"B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu cho m√£: {ma_co_phieu} t·ª´ vnstock")
    print(f"Th·ªùi gian: t·ª´ {start_date} ƒë·∫øn {end_date}")
    
    def _vnstock_api_call():
        """Internal function ƒë·ªÉ g·ªçi vnstock API"""
        stock = Vnstock().stock(symbol=ma_co_phieu, source='VCI')
        return stock.quote.history(start=start_date, end=end_date, interval='1D')
    
    try:
        # üõ°Ô∏è S·ª≠ d·ª•ng rate-limited call ƒë·ªÉ b·∫£o v·ªá API
        df = rate_limited_call(_vnstock_api_call)
        
        if df is not None and not df.empty:
            print("L·∫•y d·ªØ li·ªáu th√†nh c√¥ng!")
            return df
        else:
            print(f"Kh√¥ng c√≥ d·ªØ li·ªáu cho m√£ {ma_co_phieu} trong kho·∫£ng th·ªùi gian y√™u c·∫ßu.")
            return None
            
    except Exception as e:
        error_str = str(e).lower()
        if "rate" in error_str or "limit" in error_str or "quota" in error_str:
            print(f"üõ°Ô∏è Rate limit ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi rate limiter: {e}")
        else:
            print(f"L·ªói khi l·∫•y d·ªØ li·ªáu: {e}")
        print("C√≥ th·ªÉ th·ª≠ l·∫°i sau ho·∫∑c ki·ªÉm tra l·∫°i m√£ c·ªï phi·∫øu")
        return None

def tinh_toan_chi_bao_ky_thuat(df: pd.DataFrame):
    """
    H√†m n√†y nh·∫≠n v√†o m·ªôt DataFrame v√† t√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t theo h·ªá th·ªëng GTI.
    """
    print("\nB·∫Øt ƒë·∫ßu t√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t theo h·ªá th·ªëng GTI...")
    
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # 1. C√°c ƒë∆∞·ªùng EMA theo h·ªá th·ªëng GTI
    df['EMA10'] = ta.trend.EMAIndicator(df['close'], window=10).ema_indicator()
    df['EMA20'] = ta.trend.EMAIndicator(df['close'], window=20).ema_indicator()
    df['EMA50'] = ta.trend.EMAIndicator(df['close'], window=50).ema_indicator()
    df['EMA200'] = ta.trend.EMAIndicator(df['close'], window=200).ema_indicator()
    
    # 2. T√≠nh to√°n kh·ªëi l∆∞·ª£ng trung b√¨nh 20 phi√™n
    df['volume_avg_20'] = df['volume'].rolling(window=20).mean()
    
    # 3. T√≠nh to√°n ƒë·ªânh 1 nƒÉm (252 phi√™n giao d·ªãch)
    df['high_1_year'] = df['high'].rolling(window=252, min_periods=1).max()
    
    # 4. GTI Trend Check: EMA10 > EMA20 v√† price > EMA10 > EMA20
    df['gti_trend_check'] = (
        (df['EMA10'] > df['EMA20']) & 
        (df['close'] > df['EMA10']) & 
        (df['close'] > df['EMA20'])
    )
    
    # 5. GTI Recent Breakout: Volume > 1.5x trung b√¨nh v√† gi√° tƒÉng m·∫°nh
    # Ki·ªÉm tra trong 5 phi√™n g·∫ßn nh·∫•t c√≥ breakout kh√¥ng
    df['volume_breakout'] = df['volume'] > (df['volume_avg_20'] * 1.5)
    df['price_increase'] = (df['close'] - df['close'].shift(1)) / df['close'].shift(1) > 0.03  # TƒÉng > 3%
    df['daily_breakout'] = df['volume_breakout'] & df['price_increase']
    df['gti_recent_breakout'] = df['daily_breakout'].rolling(window=5).max().fillna(False).astype(bool)
    
    # 6. GTI Distance to High: Kho·∫£ng c√°ch ƒë·∫øn ƒë·ªânh 1 nƒÉm (%)
    df['gti_dist_to_high_percent'] = ((df['high_1_year'] - df['close']) / df['close'] * 100).round(2)
    
    # 7. GTI Pullback Check: Gi√° g·∫ßn EMA10 ho·∫∑c EMA20 (trong v√≤ng 2%)
    df['distance_to_ema10_percent'] = abs((df['close'] - df['EMA10']) / df['EMA10'] * 100)
    df['distance_to_ema20_percent'] = abs((df['close'] - df['EMA20']) / df['EMA20'] * 100)
    df['gti_is_pullback'] = (
        (df['distance_to_ema10_percent'] <= 2.0) | 
        (df['distance_to_ema20_percent'] <= 2.0)
    )
    
    # 8. C√°c ch·ªâ b√°o k·ªπ thu·∫≠t truy·ªÅn th·ªëng (gi·ªØ l·∫°i cho tham kh·∫£o)
    df['RSI'] = ta.momentum.RSIIndicator(df['close']).rsi()
    macd = ta.trend.MACD(df['close'])
    df['MACD'] = macd.macd()
    df['MACD_signal'] = macd.macd_signal()
    df['SMA_20'] = ta.trend.SMAIndicator(df['close'], window=20).sma_indicator()
    
    # 9. GTI Overall Score: T·ªïng ƒëi·ªÉm GTI (0-4)
    df['gti_score'] = (
        df['gti_trend_check'].astype(int) +
        df['gti_recent_breakout'].astype(int) +
        (df['gti_dist_to_high_percent'] <= 15).astype(int) +  # G·∫ßn ƒë·ªânh (c√°ch < 15%)
        df['gti_is_pullback'].astype(int)
    )
    
    # 10. GTI Signal: T√≠n hi·ªáu mua/b√°n theo GTI
    df['gti_signal'] = 'HOLD'
    df.loc[df['gti_score'] >= 3, 'gti_signal'] = 'BUY'
    df.loc[df['gti_score'] <= 1, 'gti_signal'] = 'AVOID'
    
    print("T√≠nh to√°n c√°c ch·ªâ b√°o GTI ho√†n t·∫•t!")
    return df

def detect_free_patterns(df: pd.DataFrame):
    """
    H√†m mi·ªÖn ph√≠ ƒë·ªÉ detect c√°c patterns ph·ªï bi·∫øn - kh√¥ng c·∫ßn th∆∞ vi·ªán tr·∫£ ph√≠
    Ho√†n to√†n t·ª± code d·ª±a tr√™n logic OHLC
    """
    print("\nB·∫Øt ƒë·∫ßu ph√°t hi·ªán patterns mi·ªÖn ph√≠...")
    
    # T·∫°o b·∫£n sao
    df = df.copy()
    
    # T√≠nh to√°n c√°c gi√° tr·ªã c∆° b·∫£n
    df['body_size'] = abs(df['close'] - df['open'])
    df['total_range'] = df['high'] - df['low']
    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)
    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']
    df['is_bullish'] = df['close'] > df['open']
    df['is_bearish'] = df['close'] < df['open']
    
    # 1. DOJI PATTERN (n·∫øn doji - open ‚âà close)
    df['pattern_doji'] = (df['body_size'] / df['total_range']) < 0.1
    
    # 2. HAMMER PATTERN (n·∫øn b√∫a - shadow d∆∞·ªõi d√†i)
    df['pattern_hammer'] = (
        (df['lower_shadow'] > 2 * df['body_size']) & 
        (df['upper_shadow'] < df['body_size']) &
        (df['total_range'] > 0)  # Tr√°nh chia cho 0
    )
    
    # 3. HANGING MAN (n·∫øn treo c·ªï - gi·ªëng hammer nh∆∞ng ·ªü ƒë·ªânh)
    df['pattern_hanging_man'] = (
        df['pattern_hammer'] & 
        (df['close'] < df['close'].shift(1))  # Gi√° gi·∫£m so v·ªõi phi√™n tr∆∞·ªõc
    )
    
    # 4. BULLISH ENGULFING (n·∫øn bao ph·ªß tƒÉng)
    prev_bearish = df['is_bearish'].shift(1)
    curr_bullish = df['is_bullish']
    engulfs = (df['open'] <= df['close'].shift(1)) & (df['close'] >= df['open'].shift(1))
    df['pattern_bullish_engulfing'] = prev_bearish & curr_bullish & engulfs
    
    # 5. BEARISH ENGULFING (n·∫øn bao ph·ªß gi·∫£m)
    prev_bullish = df['is_bullish'].shift(1)
    curr_bearish = df['is_bearish']
    engulfs_bear = (df['open'] >= df['close'].shift(1)) & (df['close'] <= df['open'].shift(1))
    df['pattern_bearish_engulfing'] = prev_bullish & curr_bearish & engulfs_bear
    
    # 6. MORNING STAR (sao mai - 3 n·∫øn)
    # N·∫øn 1: bearish, N·∫øn 2: doji/small body, N·∫øn 3: bullish
    cond1 = df['is_bearish'].shift(2)  # N·∫øn 1 gi·∫£m
    cond2 = (df['body_size'].shift(1) / df['total_range'].shift(1)) < 0.3  # N·∫øn 2 th√¢n nh·ªè
    cond3 = df['is_bullish']  # N·∫øn 3 tƒÉng
    cond4 = df['close'] > df['close'].shift(2)  # N·∫øn 3 cao h∆°n n·∫øn 1
    df['pattern_morning_star'] = cond1 & cond2 & cond3 & cond4
    
    # 7. EVENING STAR (sao h√¥m - 3 n·∫øn)
    cond1_eve = df['is_bullish'].shift(2)  # N·∫øn 1 tƒÉng
    cond2_eve = (df['body_size'].shift(1) / df['total_range'].shift(1)) < 0.3  # N·∫øn 2 th√¢n nh·ªè
    cond3_eve = df['is_bearish']  # N·∫øn 3 gi·∫£m
    cond4_eve = df['close'] < df['close'].shift(2)  # N·∫øn 3 th·∫•p h∆°n n·∫øn 1
    df['pattern_evening_star'] = cond1_eve & cond2_eve & cond3_eve & cond4_eve
    
    # 8. SUPPORT/RESISTANCE LEVELS (ƒë∆°n gi·∫£n)
    window = 20
    df['resistance_level'] = df['high'].rolling(window=window).max().shift(1)
    df['support_level'] = df['low'].rolling(window=window).min().shift(1)
    
    # 9. BREAKOUT PATTERNS
    df['pattern_resistance_breakout'] = (
        (df['close'] > df['resistance_level']) & 
        (df['volume'] > df['volume'].rolling(window=20).mean() * 1.2)  # Volume cao
    )
    
    df['pattern_support_breakdown'] = (
        (df['close'] < df['support_level']) & 
        (df['volume'] > df['volume'].rolling(window=20).mean() * 1.2)  # Volume cao
    )
    
    # 10. VOLUME SPIKE PATTERN
    df['volume_avg_20'] = df['volume'].rolling(window=20).mean()
    df['pattern_volume_spike'] = df['volume'] > (df['volume_avg_20'] * 2)
    
    # 11. GAP PATTERNS
    df['gap_up'] = df['low'] > df['high'].shift(1)
    df['gap_down'] = df['high'] < df['low'].shift(1)
    df['pattern_gap_up'] = df['gap_up'] & df['is_bullish']
    df['pattern_gap_down'] = df['gap_down'] & df['is_bearish']
    
    # 12. SIMPLE TREND PATTERNS
    df['trend_5d'] = df['close'].rolling(5).apply(lambda x: 1 if x.iloc[-1] > x.iloc[0] else 0)
    df['pattern_strong_uptrend'] = (
        (df['trend_5d'] == 1) & 
        (df['close'] > df['close'].rolling(10).mean()) &
        (df['volume'] > df['volume_avg_20'])
    )
    
    print("Ph√°t hi·ªán patterns mi·ªÖn ph√≠ ho√†n t·∫•t!")
    return df

def phan_tich_pattern_results(df: pd.DataFrame, ma_co_phieu: str):
    """
    Ph√¢n t√≠ch k·∫øt qu·∫£ patterns v√† ƒë∆∞a ra b√°o c√°o
    """
    print(f"\nüìä B√ÅO C√ÅO PATTERNS CHO M√É {ma_co_phieu}")
    print("="*50)
    
    # L·∫•y d·ªØ li·ªáu 10 phi√™n g·∫ßn nh·∫•t
    recent_data = df.tail(10)
    latest = df.iloc[-1]
    
    # ƒê·∫øm patterns trong 10 phi√™n g·∫ßn nh·∫•t
    pattern_columns = [col for col in df.columns if col.startswith('pattern_')]
    
    print("üîç PATTERNS PH√ÅT HI·ªÜN TRONG 10 PHI√äN G·∫¶N NH·∫§T:")
    for pattern in pattern_columns:
        count = recent_data[pattern].sum()
        if count > 0:
            pattern_name = pattern.replace('pattern_', '').replace('_', ' ').title()
            print(f"   ‚úÖ {pattern_name}: {count} l·∫ßn")
    
    print(f"\nüìà TH√îNG TIN PHI√äN G·∫¶N NH·∫§T ({latest.name}):")
    print(f"   Gi√° ƒë√≥ng c·ª≠a: {latest['close']:,.0f} VND")
    print(f"   Kh·ªëi l∆∞·ª£ng: {latest['volume']:,.0f}")
    print(f"   Support level: {latest['support_level']:,.0f} VND")
    print(f"   Resistance level: {latest['resistance_level']:,.0f} VND")
    
    print(f"\nüéØ PATTERNS HI·ªÜN T·∫†I:")
    current_patterns = []
    for pattern in pattern_columns:
        if latest[pattern]:
            pattern_name = pattern.replace('pattern_', '').replace('_', ' ').title()
            current_patterns.append(pattern_name)
    
    if current_patterns:
        for p in current_patterns:
            print(f"   üî• {p}")
    else:
        print("   ‚û°Ô∏è  Kh√¥ng c√≥ pattern ƒë·∫∑c bi·ªát")
    
    # T√≠nh ƒëi·ªÉm pattern t·ªïng h·ª£p (bao g·ªìm c·∫£ large patterns)
    bullish_patterns = ['bullish_engulfing', 'morning_star', 'hammer', 'resistance_breakout', 'gap_up', 'strong_uptrend']
    bearish_patterns = ['bearish_engulfing', 'evening_star', 'hanging_man', 'support_breakdown', 'gap_down']
    
    # Th√™m large patterns (c√≥ ƒëi·ªÉm cao h∆°n do quan tr·ªçng h∆°n)
    large_bullish_patterns = ['cup_handle', 'bull_flag', 'base_n_break', 'ascending_triangle']
    
    # ƒêi·ªÉm cho patterns th∆∞·ªùng
    bullish_score = sum([latest[f'pattern_{p}'] for p in bullish_patterns if f'pattern_{p}' in df.columns])
    bearish_score = sum([latest[f'pattern_{p}'] for p in bearish_patterns if f'pattern_{p}' in df.columns])
    
    # ƒêi·ªÉm cho large patterns (x2 do quan tr·ªçng h∆°n)
    large_bullish_score = sum([latest[f'pattern_{p}'] * 2 for p in large_bullish_patterns if f'pattern_{p}' in df.columns])
    
    # T·ªïng ƒëi·ªÉm bullish
    bullish_score += large_bullish_score
    
    print(f"\n‚öñÔ∏è  ƒêI·ªÇM PATTERN T·ªîNG H·ª¢P:")
    print(f"   Bullish Score: {bullish_score}")
    print(f"   Bearish Score: {bearish_score}")
    
    if bullish_score > bearish_score:
        print(f"   üìà Xu h∆∞·ªõng: T√çCH C·ª∞C")
    elif bearish_score > bullish_score:
        print(f"   üìâ Xu h∆∞·ªõng: TI√äU C·ª∞C") 
    else:
        print(f"   ‚û°Ô∏è  Xu h∆∞·ªõng: TRUNG T√çNH")
    
    # ‚úÖ GI·∫¢I PH√ÅP: √âp ki·ªÉu v·ªÅ int ti√™u chu·∫©n c·ªßa Python tr∆∞·ªõc khi tr·∫£ v·ªÅ
    return {
        'bullish_score': int(bullish_score),
        'bearish_score': int(bearish_score),
        'current_patterns': current_patterns,
        'latest_data': latest
    }

def detect_large_chart_patterns(df: pd.DataFrame, lookback_window: int = 60):
    """
    üîç Ph√°t hi·ªán c√°c m·∫´u h√¨nh l·ªõn (Large Chart Patterns)
    - Cup & Handle
    - Bull Flag / Bear Flag  
    - Base n' Break
    - Ascending/Descending Triangle
    """
    print("\nüîç B·∫Øt ƒë·∫ßu ph√°t hi·ªán m·∫´u h√¨nh l·ªõn...")
    
    df = df.copy()
    
    # T√≠nh to√°n rolling max/min cho pattern detection
    df['rolling_high_20'] = df['high'].rolling(window=20).max()
    df['rolling_low_20'] = df['low'].rolling(window=20).min()
    df['rolling_high_60'] = df['high'].rolling(window=60).max()
    df['rolling_low_60'] = df['low'].rolling(window=60).min()
    
    # 1. CUP & HANDLE PATTERN
    def detect_cup_and_handle(df_local, window=50):
        """Ph√°t hi·ªán m·∫´u h√¨nh Cup & Handle"""
        patterns = []
        
        for i in range(window, len(df_local) - 10):
            # L·∫•y d·ªØ li·ªáu trong window
            data_window = df_local.iloc[i-window:i+10]
            
            # T√¨m 2 ƒë·ªânh cao nh·∫•t (left rim, right rim)
            high_peaks = data_window['high'].nlargest(3)
            
            if len(high_peaks) >= 2:
                # Cup: c√≥ ƒë√°y s√¢u gi·ªØa 2 ƒë·ªânh
                left_peak = high_peaks.iloc[0]
                right_peak = high_peaks.iloc[1]
                
                # Cup depth should be 12-33% of left peak
                cup_depth_ratio = (left_peak - data_window['low'].min()) / left_peak
                
                if 0.12 <= cup_depth_ratio <= 0.33:
                    # Handle: pullback < 50% of cup depth
                    handle_start = i
                    recent_data = df_local.iloc[handle_start:handle_start+10]
                    
                    if len(recent_data) > 5:
                        handle_depth = (recent_data['high'].max() - recent_data['low'].min()) / recent_data['high'].max()
                        
                        if handle_depth < (cup_depth_ratio * 0.5):
                            patterns.append(i)
        
        return patterns
    
    cup_handle_patterns = detect_cup_and_handle(df)
    df['pattern_cup_handle'] = False
    if cup_handle_patterns:
        for idx in cup_handle_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_cup_handle')] = True
    
    # 2. BULL FLAG PATTERN
    def detect_bull_flag(df_local, window=30):
        """Ph√°t hi·ªán m·∫´u h√¨nh Bull Flag"""
        patterns = []
        
        for i in range(window, len(df_local) - 5):
            # Flagpole: Strong upward move
            flagpole_data = df_local.iloc[i-window:i-10]
            recent_data = df_local.iloc[i-10:i]
            
            # Check for strong upward move (flagpole)
            flagpole_gain = (flagpole_data['close'].iloc[-1] - flagpole_data['close'].iloc[0]) / flagpole_data['close'].iloc[0]
            
            if flagpole_gain > 0.15:  # At least 15% gain
                # Flag: slight downward or sideways consolidation
                flag_slope = (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / len(recent_data)
                flag_range = (recent_data['high'].max() - recent_data['low'].min()) / recent_data['close'].mean()
                
                # Flag should be small consolidation
                if -0.08 <= flag_slope <= 0.03 and flag_range < 0.15:
                    # Volume should decrease during flag
                    volume_trend = recent_data['volume'].iloc[-3:].mean() < flagpole_data['volume'].iloc[-3:].mean()
                    if volume_trend:
                        patterns.append(i)
        
        return patterns
    
    bull_flag_patterns = detect_bull_flag(df)
    df['pattern_bull_flag'] = False
    if bull_flag_patterns:
        for idx in bull_flag_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_bull_flag')] = True
    
    # 3. BASE N' BREAK PATTERN
    def detect_base_n_break(df_local, window=40):
        """Ph√°t hi·ªán m·∫´u h√¨nh Base n' Break"""
        patterns = []
        
        for i in range(window, len(df_local) - 3):
            base_data = df_local.iloc[i-window:i]
            
            # Base: tight sideways consolidation
            base_range = (base_data['high'].max() - base_data['low'].min()) / base_data['close'].mean()
            
            # Base should be tight (< 20% range)
            if base_range < 0.20:
                # Check for decreasing volatility in base
                early_base = base_data.iloc[:len(base_data)//2]
                late_base = base_data.iloc[len(base_data)//2:]
                
                early_volatility = (early_base['high'] - early_base['low']).mean() / early_base['close'].mean()
                late_volatility = (late_base['high'] - late_base['low']).mean() / late_base['close'].mean()
                
                # Volatility contraction
                if late_volatility < early_volatility:
                    # Breakout: price breaks above base resistance with volume
                    resistance_level = base_data['high'].max()
                    current_price = df_local.iloc[i]['close']
                    current_volume = df_local.iloc[i]['volume']
                    avg_volume = base_data['volume'].mean()
                    
                    if current_price > resistance_level and current_volume > (avg_volume * 1.5):
                        patterns.append(i)
        
        return patterns
    
    base_break_patterns = detect_base_n_break(df)
    df['pattern_base_n_break'] = False
    if base_break_patterns:
        for idx in base_break_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_base_n_break')] = True
    
    # 4. ASCENDING TRIANGLE
    def detect_ascending_triangle(df_local, window=30):
        """Ph√°t hi·ªán m·∫´u h√¨nh Ascending Triangle"""
        patterns = []
        
        for i in range(window, len(df_local) - 5):
            triangle_data = df_local.iloc[i-window:i]
            
            # Resistance: horizontal line (multiple touches at same level)
            resistance_level = triangle_data['high'].max()
            resistance_touches = len(triangle_data[triangle_data['high'] >= resistance_level * 0.99])
            
            # Support: rising trend line
            lows = triangle_data['low']
            time_index = range(len(lows))
            
            # Simple rising support check
            first_quarter_low = lows.iloc[:len(lows)//4].min()
            last_quarter_low = lows.iloc[-len(lows)//4:].min()
            
            if resistance_touches >= 2 and last_quarter_low > first_quarter_low:
                # Breakout above resistance
                current_price = df_local.iloc[i]['close']
                current_volume = df_local.iloc[i]['volume']
                avg_volume = triangle_data['volume'].mean()
                
                if current_price > resistance_level and current_volume > (avg_volume * 1.3):
                    patterns.append(i)
        
        return patterns
    
    ascending_triangle_patterns = detect_ascending_triangle(df)
    df['pattern_ascending_triangle'] = False
    if ascending_triangle_patterns:
        for idx in ascending_triangle_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_ascending_triangle')] = True
    
    print("‚úÖ Ho√†n th√†nh ph√°t hi·ªán m·∫´u h√¨nh l·ªõn!")
    return df

def get_market_context():
    """
    üåä L·∫•y b·ªëi c·∫£nh th·ªã tr∆∞·ªùng chung (VNINDEX) theo h·ªá th·ªëng GTI
    """
    print("\nüåä ƒêang ph√¢n t√≠ch b·ªëi c·∫£nh th·ªã tr∆∞·ªùng...")
    
    try:
        # L·∫•y d·ªØ li·ªáu VNINDEX
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        vnindex_df = lay_du_lieu_co_phieu_vnstock("VNINDEX", start_date, end_date)
        
        if vnindex_df is None or vnindex_df.empty:
            return {
                "status": "error",
                "message": "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu VNINDEX"
            }
        
        # T√≠nh to√°n GTI cho VNINDEX
        vnindex_gti = tinh_toan_chi_bao_ky_thuat(vnindex_df)
        latest_vnindex = vnindex_gti.iloc[-1]
        
        # Ph√¢n t√≠ch trend VNINDEX
        vnindex_trend = "UPTREND" if latest_vnindex['gti_trend_check'] else "SIDEWAY/DOWNTREND"
        vnindex_score = int(latest_vnindex['gti_score'])
        
        # ƒê√°nh gi√° hi·ªáu qu·∫£ GTI theo market phase
        if vnindex_trend == "UPTREND" and vnindex_score >= 3:
            effectiveness = "CAO (70-80%)"
            recommendation = "Th√≠ch h·ª£p cho chi·∫øn l∆∞·ª£c t√≠ch c·ª±c"
            max_position = "8-10% NAV per stock"
        elif vnindex_score >= 2:
            effectiveness = "TRUNG B√åNH (50-60%)" 
            recommendation = "Gi·∫£m t·ª∑ tr·ªçng, ch·ªçn l·ªçc k·ªπ"
            max_position = "5-7% NAV per stock"
        else:
            effectiveness = "TH·∫§P (<50%)"
            recommendation = "Tr√°nh xa ho·∫∑c trade v·ªõi ƒëi·ªÉm ‚â•5"
            max_position = "3-5% NAV per stock"
        
        market_context = {
            "status": "success",
            "vnindex": {
                "current_price": round(float(latest_vnindex['close']), 2),
                "gti_score": vnindex_score,
                "trend": vnindex_trend,
                "trend_check": bool(latest_vnindex['gti_trend_check']),
                "recent_breakout": bool(latest_vnindex['gti_recent_breakout']),
                "near_high": bool(latest_vnindex['gti_dist_to_high_percent'] <= 15),
                "dist_to_high": round(float(latest_vnindex['gti_dist_to_high_percent']), 2)
            },
            "gti_effectiveness": {
                "current_market": vnindex_trend,
                "effectiveness_rate": effectiveness,
                "recommendation": recommendation,
                "max_position_size": max_position
            },
            "analysis_note": f"VNINDEX ƒëang ·ªü giai ƒëo·∫°n {vnindex_trend} v·ªõi GTI score {vnindex_score}/4. "
                           f"ƒê·ªô ch√≠nh x√°c h·ªá th·ªëng GTI ∆∞·ªõc t√≠nh: {effectiveness}."
        }
        
        print(f"‚úÖ VNINDEX: {latest_vnindex['close']:.1f} | GTI: {vnindex_score}/4 | Trend: {vnindex_trend}")
        return market_context
        
    except Exception as e:
        print(f"‚ùå L·ªói ph√¢n t√≠ch market context: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch th·ªã tr∆∞·ªùng: {str(e)}"
        }

def get_sector_analysis(stock_symbol: str):
    """
    üè≠ Ph√¢n t√≠ch ch·ªâ s·ªë ng√†nh (ƒë∆°n gi·∫£n ho√° - s·ª≠ d·ª•ng c√°c m√£ ƒë·∫°i di·ªán)
    """
    print(f"\nüè≠ ƒêang ph√¢n t√≠ch ng√†nh cho {stock_symbol}...")
    
    # Mapping m√£ c·ªï phi·∫øu v·ªõi ng√†nh v√† m√£ ƒë·∫°i di·ªán
    sector_mapping = {
        # Banking
        "ACB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "BID": {"sector": "Ng√¢n h√†ng", "representative": "VCB"}, 
        "CTG": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "HDB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "MBB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "STB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "TCB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "TPB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VCB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VPB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VIB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        
        # Real Estate
        "VHM": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        "VIC": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        "VRE": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        
        # Technology
        "FPT": {"sector": "C√¥ng ngh·ªá", "representative": "FPT"},
        
        # Steel
        "HPG": {"sector": "Th√©p", "representative": "HPG"},
        
        # Retail
        "MWG": {"sector": "B√°n l·∫ª", "representative": "MWG"},
        
        # Oil & Gas
        "GAS": {"sector": "D·∫ßu kh√≠", "representative": "GAS"},
        "PLX": {"sector": "D·∫ßu kh√≠", "representative": "GAS"},
        
        # Food & Beverage
        "VNM": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
        "MSN": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
        "SAB": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
    }
    
    sector_info = sector_mapping.get(stock_symbol.upper())
    
    if not sector_info:
        return {
            "status": "unknown_sector",
            "message": f"Ch∆∞a c√≥ th√¥ng tin ng√†nh cho {stock_symbol}"
        }
    
    try:
        # L·∫•y d·ªØ li·ªáu m√£ ƒë·∫°i di·ªán ng√†nh
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        sector_df = lay_du_lieu_co_phieu_vnstock(sector_info["representative"], start_date, end_date)
        
        if sector_df is None or sector_df.empty:
            return {
                "status": "error", 
                "message": f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu ng√†nh {sector_info['sector']}"
            }
        
        # T√≠nh GTI cho ng√†nh
        sector_gti = tinh_toan_chi_bao_ky_thuat(sector_df)
        latest_sector = sector_gti.iloc[-1]
        sector_score = int(latest_sector['gti_score'])
        
        sector_trend = "T√çCH C·ª∞C" if latest_sector['gti_trend_check'] else "TI√äU C·ª∞C"
        
        sector_analysis = {
            "status": "success",
            "sector_name": sector_info["sector"],
            "representative_stock": sector_info["representative"],
            "sector_gti_score": sector_score,
            "sector_trend": sector_trend,
            "sector_price": round(float(latest_sector['close']), 2),
            "analysis_note": f"Ng√†nh {sector_info['sector']} (ƒë·∫°i di·ªán: {sector_info['representative']}) "
                           f"c√≥ GTI score {sector_score}/4, xu h∆∞·ªõng {sector_trend}."
        }
        
        print(f"‚úÖ Ng√†nh {sector_info['sector']}: GTI {sector_score}/4 | {sector_trend}")
        return sector_analysis
        
    except Exception as e:
        print(f"‚ùå L·ªói ph√¢n t√≠ch ng√†nh: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch ng√†nh: {str(e)}"
        }

def prepare_news_search_context(stock_symbol: str, sector_name: str = None):
    """
    üì∞ Chu·∫©n b·ªã context cho ChatGPT search tin t·ª©c
    QUAN TR·ªåNG: Ch·ªâ search tin t·ª©c, s·ª± ki·ªán - KH√îNG search d·ªØ li·ªáu gi√°, volume, ch·ªâ s·ªë k·ªπ thu·∫≠t
    """
    search_contexts = {
        "company_news": f"tin t·ª©c m·ªõi nh·∫•t v·ªÅ c√¥ng ty {stock_symbol} Vi·ªát Nam",
        "earnings_news": f"k·∫øt qu·∫£ kinh doanh {stock_symbol} 2024 2025",
        "industry_events": f"tin t·ª©c ng√†nh {sector_name if sector_name else 'ch·ª©ng kho√°n'} Vi·ªát Nam",
        "policy_updates": f"ch√≠nh s√°ch ·∫£nh h∆∞·ªüng ng√†nh {sector_name if sector_name else 't√†i ch√≠nh'} Vi·ªát Nam"
    }
    
    return {
        "search_instruction": f"""
üîç H∆Ø·ªöNG D·∫™N SEARCH TIN T·ª®C CHO {stock_symbol}:

‚úÖ C·∫¶N T√åM:
- Tin t·ª©c c√¥ng ty: {search_contexts['company_news']}
- K·∫øt qu·∫£ kinh doanh: {search_contexts['earnings_news']}
- S·ª± ki·ªán ng√†nh: {search_contexts['industry_events']}
- Ch√≠nh s√°ch li√™n quan: {search_contexts['policy_updates']}

‚ùå TUY·ªÜT ƒê·ªêI KH√îNG T√åM:
- D·ªØ li·ªáu gi√° c·ªï phi·∫øu, volume, ch·ªâ s·ªë k·ªπ thu·∫≠t
- D·ª± ƒëo√°n gi√°, forecast
- Ph√¢n t√≠ch k·ªπ thu·∫≠t t·ª´ b√™n ngo√†i

üìä L∆ØU √ù: T·∫•t c·∫£ d·ªØ li·ªáu v·ªÅ gi√° v√† ch·ªâ s·ªë k·ªπ thu·∫≠t ƒë√£ ƒë∆∞·ª£c cung c·∫•p qua API.
        """,
        "suggested_searches": list(search_contexts.values())
    }

def comprehensive_gti_analysis(stock_symbol: str, start_date: str = None, end_date: str = None):
    """
    üöÄ Ph√¢n t√≠ch GTI Pro v2.0 TO√ÄN DI·ªÜN:
    1. GTI Core (4 ti√™u ch√≠) + Enhanced Patterns (16 patterns)
    2. Market Context (VNINDEX) + Sector Analysis
    3. News Search Context cho ChatGPT
    4. Combined Scoring & Recommendations
    """
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH GTI PRO v2.0 TO√ÄN DI·ªÜN CHO {stock_symbol}")
    print("="*80)
    
    # T√≠nh to√°n th·ªùi gian m·∫∑c ƒë·ªãnh
    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if not start_date:
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
    
    try:
        # B∆Ø·ªöC 1: L·∫•y d·ªØ li·ªáu c∆° b·∫£n
        print("üìä B∆Ø·ªöC 1: L·∫•y d·ªØ li·ªáu c∆° b·∫£n...")
        df = lay_du_lieu_co_phieu_vnstock(stock_symbol, start_date, end_date)
        
        if df is None or df.empty:
            return {
                "status": "error",
                "message": f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho {stock_symbol}"
            }
        
        # B∆Ø·ªöC 2: GTI Core Analysis
        print("üî• B∆Ø·ªöC 2: Ph√¢n t√≠ch GTI Core...")
        df_gti = tinh_toan_chi_bao_ky_thuat(df)
        
        # B∆Ø·ªöC 3: Basic Pattern Detection
        print("üéØ B∆Ø·ªöC 3: Ph√°t hi·ªán Basic Patterns...")
        df_patterns = detect_free_patterns(df_gti)
        
        # B∆Ø·ªöC 4: Large Chart Patterns  
        print("üìà B∆Ø·ªöC 4: Ph√°t hi·ªán Large Chart Patterns...")
        df_patterns = detect_large_chart_patterns(df_patterns)
        
        # B∆Ø·ªöC 5: Pattern Analysis
        print("üìä B∆Ø·ªöC 5: Ph√¢n t√≠ch Pattern Results...")
        pattern_results = phan_tich_pattern_results(df_patterns, stock_symbol)
        
        # B∆Ø·ªöC 6: Market Context Analysis
        print("üåä B∆Ø·ªöC 6: Ph√¢n t√≠ch Market Context...")
        market_context = get_market_context()
        
        # B∆Ø·ªöC 7: Sector Analysis
        print("üè≠ B∆Ø·ªöC 7: Ph√¢n t√≠ch Sector...")
        sector_analysis = get_sector_analysis(stock_symbol)
        
        # B∆Ø·ªöC 8: News Search Context
        print("üì∞ B∆Ø·ªöC 8: Chu·∫©n b·ªã News Search Context...")
        sector_name = sector_analysis.get('sector_name') if sector_analysis.get('status') == 'success' else None
        news_context = prepare_news_search_context(stock_symbol, sector_name)
        
        # B∆Ø·ªöC 9: Combined Scoring v2.0
        print("‚ö° B∆Ø·ªöC 9: T√≠nh to√°n Enhanced Scoring...")
        latest = df_patterns.iloc[-1]
        
        # GTI Score (0-4) - √©p ki·ªÉu v·ªÅ int Python
        gti_score = int(latest['gti_score']) if pd.notna(latest['gti_score']) else 0
        
        # Basic Pattern Scores - ƒë·∫£m b·∫£o ki·ªÉu int Python
        basic_bullish = int(pattern_results.get('bullish_score', 0))
        basic_bearish = int(pattern_results.get('bearish_score', 0))
        
        # Large Pattern Scores (√ó2 points)
        large_patterns = ['cup_handle', 'bull_flag', 'base_n_break', 'ascending_triangle']
        large_bullish_score = 0
        for pattern in large_patterns:
            if f'pattern_{pattern}' in df_patterns.columns and latest[f'pattern_{pattern}']:
                large_bullish_score += 2  # Large patterns worth 2 points each
        
        # Base Score: GTI + Basic + Large
        base_score = gti_score + basic_bullish - basic_bearish + large_bullish_score
        
        # Market Context Adjustments
        market_adjustment = 0
        if market_context.get('status') == 'success':
            vnindex_gti = market_context['vnindex']['gti_score']
            if vnindex_gti >= 3:  # VNINDEX uptrend
                market_adjustment += 0.5
            elif vnindex_gti <= 1:  # VNINDEX downtrend
                market_adjustment -= 0.5
        
        # Sector Adjustment
        sector_adjustment = 0
        if sector_analysis.get('status') == 'success':
            if sector_analysis['sector_trend'] == 'T√çCH C·ª∞C':
                sector_adjustment += 0.25
            elif sector_analysis['sector_trend'] == 'TI√äU C·ª∞C':
                sector_adjustment -= 0.25
        
        # Final Combined Score
        combined_score = base_score + market_adjustment + sector_adjustment
        
        # Enhanced Recommendations
        if combined_score >= 6:
            recommendation = {
                "level": "C·ª∞C K·ª≤ T√çCH C·ª∞C", 
                "action": "STRONG BUY",
                "emoji": "üü¢",
                "position_size": "8-12% NAV",
                "message": "C∆° h·ªôi ƒë·∫ßu t∆∞ xu·∫•t s·∫Øc v·ªõi ƒëi·ªÉm s·ªë cao"
            }
        elif combined_score >= 4:
            recommendation = {
                "level": "R·∫§T T√çCH C·ª∞C", 
                "action": "C√ÇN NH·∫ÆC MUA",
                "emoji": "üü¢", 
                "position_size": "5-8% NAV",
                "message": "C∆° h·ªôi t·ªët, c√¢n nh·∫Øc mua v√†o"
            }
        elif combined_score >= 2:
            recommendation = {
                "level": "T√çCH C·ª∞C", 
                "action": "THEO D√ïI",
                "emoji": "üü°",
                "position_size": "3-5% NAV", 
                "message": "Theo d√µi v√† ch·ªù t√≠n hi·ªáu r√µ h∆°n"
            }
        elif combined_score >= 0:
            recommendation = {
                "level": "TRUNG T√çNH", 
                "action": "CH·ªú T√çN HI·ªÜU",
                "emoji": "üü†",
                "position_size": "0-3% NAV",
                "message": "Ch∆∞a c√≥ t√≠n hi·ªáu r√µ r√†ng, ch·ªù ƒë·ª£i"
            }
        else:
            recommendation = {
                "level": "TI√äU C·ª∞C", 
                "action": "TR√ÅNH XA",
                "emoji": "üî¥",
                "position_size": "0% NAV", 
                "message": "Tr√°nh xa ho·∫∑c ch·ªù c·∫£i thi·ªán"
            }
        
        # B∆Ø·ªöC 10: T·∫°o k·∫øt qu·∫£ comprehensive
        result = {
            "status": "success",
            "analysis_date": latest.name.strftime("%Y-%m-%d") if hasattr(latest.name, 'strftime') else str(latest.name),
            "stock_symbol": stock_symbol.upper(),
            "closing_price": round(float(latest['close']), 2),
            
            # GTI Analysis
            "gti_analysis": {
                "gti_score": int(gti_score),
                "gti_criteria": {
                    "trend_check": bool(latest['gti_trend_check']) if pd.notna(latest['gti_trend_check']) else False,
                    "recent_breakout": bool(latest['gti_recent_breakout']) if pd.notna(latest['gti_recent_breakout']) else False,
                    "near_one_year_high": bool(latest['gti_dist_to_high_percent'] <= 15) if pd.notna(latest['gti_dist_to_high_percent']) else False,
                    "is_pullback": bool(latest['gti_is_pullback']) if pd.notna(latest['gti_is_pullback']) else False
                }
            },
            
            # Enhanced Pattern Analysis
            "pattern_analysis": {
                "basic_bullish_score": int(basic_bullish),
                "basic_bearish_score": int(basic_bearish),
                "large_patterns_score": int(large_bullish_score),
                "current_patterns": pattern_results.get('current_patterns', []),
                "pattern_summary": f"{basic_bullish}B/{basic_bearish}Be + {large_bullish_score//2}L"
            },
            
            # Market Context & Sector
            "market_context": market_context,
            "sector_analysis": sector_analysis,
            
            # Combined Analysis
            "combined_analysis": {
                "base_score": int(base_score),
                "market_adjustment": market_adjustment,
                "sector_adjustment": sector_adjustment,
                "total_score": round(combined_score, 2),
                "final_recommendation": recommendation
            },
            
            # News Search Context for ChatGPT
            "news_search_context": news_context,
            
            # Technical Levels
            "technical_levels": {
                "support_level": round(float(latest['support_level']), 2) if pd.notna(latest['support_level']) else None,
                "resistance_level": round(float(latest['resistance_level']), 2) if pd.notna(latest['resistance_level']) else None,
                "EMA10": round(float(latest['EMA10']), 2) if pd.notna(latest['EMA10']) else None,
                "EMA20": round(float(latest['EMA20']), 2) if pd.notna(latest['EMA20']) else None
            },
            
            # System Info
            "system_info": {
                "version": "GTI Pro v2.0",
                "scoring_range": "-5 to +18 points",
                "enhanced_features": ["Large Patterns", "Market Context", "Sector Analysis", "News Integration"]
            }
        }
        
        print("‚úÖ HO√ÄN TH√ÄNH PH√ÇN T√çCH GTI PRO v2.0!")
        print(f"üìä K·∫æT QU·∫¢: {combined_score:.1f} ƒëi·ªÉm - {recommendation['emoji']} {recommendation['level']}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå L·ªñI PH√ÇN T√çCH: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch {stock_symbol}: {str(e)}"
        }

def scan_single_stock(stock_symbol: str, min_gti_score: int = 2, min_combined_score: int = 3):
    """
    üîç Qu√©t m·ªôt m√£ c·ªï phi·∫øu ƒë∆°n l·∫ª v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ n·∫øu ƒë·∫°t ti√™u ch√≠
    """
    try:
        # T√≠nh to√°n th·ªùi gian
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        # L·∫•y d·ªØ li·ªáu
        df = lay_du_lieu_co_phieu_vnstock(stock_symbol, start_date, end_date)
        
        if df is None or df.empty:
            return None
        
        # T√≠nh to√°n GTI
        df_analyzed = tinh_toan_chi_bao_ky_thuat(df)
        
        # Ph√°t hi·ªán patterns
        df_patterns = detect_free_patterns(df_analyzed)
        df_patterns = detect_large_chart_patterns(df_patterns)
        
        # Ph√¢n t√≠ch k·∫øt qu·∫£ patterns
        pattern_results = phan_tich_pattern_results(df_patterns, stock_symbol)
        
        # L·∫•y d·ªØ li·ªáu g·∫ßn nh·∫•t
        latest = df_patterns.iloc[-1]
        
        # T√≠nh ƒëi·ªÉm
        gti_score = int(latest['gti_score']) if pd.notna(latest['gti_score']) else 0
        bullish_score = int(pattern_results.get('bullish_score', 0))
        bearish_score = int(pattern_results.get('bearish_score', 0))
        combined_score = gti_score + bullish_score - bearish_score
        
        # L·ªçc theo ti√™u ch√≠
        if gti_score >= min_gti_score and combined_score >= min_combined_score:
            # L·∫•y ƒë√°nh gi√°
            evaluation = GTIConfig.get_score_evaluation(combined_score)
            
            return {
                "stock_symbol": stock_symbol,
                "current_price": round(float(latest['close']), 2),
                "volume": int(latest['volume']) if pd.notna(latest['volume']) else 0,
                "gti_score": gti_score,
                "pattern_score": {
                    "bullish": bullish_score,
                    "bearish": bearish_score,
                    "net": bullish_score - bearish_score
                },
                "combined_score": combined_score,
                "evaluation": evaluation,
                "key_metrics": {
                    "gti_trend_check": bool(latest['gti_trend_check']) if pd.notna(latest['gti_trend_check']) else False,
                    "gti_recent_breakout": bool(latest['gti_recent_breakout']) if pd.notna(latest['gti_recent_breakout']) else False,
                    "gti_dist_to_high_percent": round(float(latest['gti_dist_to_high_percent']), 2) if pd.notna(latest['gti_dist_to_high_percent']) else None,
                    "gti_is_pullback": bool(latest['gti_is_pullback']) if pd.notna(latest['gti_is_pullback']) else False
                },
                "technical_levels": {
                    "support": round(float(latest['support_level']), 2) if pd.notna(latest['support_level']) else None,
                    "resistance": round(float(latest['resistance_level']), 2) if pd.notna(latest['resistance_level']) else None,
                    "ema10": round(float(latest['EMA10']), 2) if pd.notna(latest['EMA10']) else None,
                    "ema20": round(float(latest['EMA20']), 2) if pd.notna(latest['EMA20']) else None
                },
                "current_patterns": pattern_results.get('current_patterns', []),
                "scan_timestamp": datetime.now().isoformat()
            }
        
        return None  # Kh√¥ng ƒë·∫°t ti√™u ch√≠
        
    except Exception as e:
        print(f"‚ùå L·ªói khi qu√©t {stock_symbol}: {str(e)}")
        return None

def market_scan_parallel(stock_list: list, 
                        min_gti_score: int = 2, 
                        min_combined_score: int = 3,
                        max_workers: int = None,
                        timeout: int = None):
    """
    üöÄ Qu√©t th·ªã tr∆∞·ªùng song song v·ªõi ThreadPoolExecutor - OPTIMIZED v2.0
    
    Args:
        stock_list: Danh s√°ch m√£ c·ªï phi·∫øu
        min_gti_score: ƒêi·ªÉm GTI t·ªëi thi·ªÉu
        min_combined_score: ƒêi·ªÉm t·ªïng h·ª£p t·ªëi thi·ªÉu
        max_workers: S·ªë thread t·ªëi ƒëa (auto-detect n·∫øu None)
        timeout: Timeout t·ªïng c·ªông (gi√¢y, auto-calculate n·∫øu None)
    
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ scan v√† th·ªëng k√™
    """
    
    # Auto-configure performance parameters
    if max_workers is None:
        max_workers = GTIConfig.MARKET_SCAN_BATCH_SIZE
    
    if timeout is None:
        # Progressive timeout: 10s base + 5s per stock, min 60s, max 600s
        if GTIConfig.ENABLE_PROGRESSIVE_TIMEOUT:
            timeout = min(max(60, 10 + len(stock_list) * 5), GTIConfig.MARKET_SCAN_TIMEOUT)
        else:
            timeout = GTIConfig.MARKET_SCAN_TIMEOUT
    
    print(f"üîç B·∫Øt ƒë·∫ßu qu√©t {len(stock_list)} m√£ c·ªï phi·∫øu song song...")
    print(f"‚öôÔ∏è  Ti√™u ch√≠: GTI >= {min_gti_score}, Combined >= {min_combined_score}")
    print(f"üîß C·∫•u h√¨nh: {max_workers} workers, timeout {timeout}s")
    
    start_time = time.time()
    results = []
    errors = []
    processed_count = 0
    
    # Chunked processing for large lists
    if len(stock_list) > GTIConfig.CHUNK_SIZE_FOR_LARGE_SCANS:
        print(f"üì¶ Chia nh·ªè {len(stock_list)} m√£ th√†nh chunks c·ªßa {GTIConfig.CHUNK_SIZE_FOR_LARGE_SCANS}")
        
        chunk_size = GTIConfig.CHUNK_SIZE_FOR_LARGE_SCANS
        for i in range(0, len(stock_list), chunk_size):
            chunk = stock_list[i:i + chunk_size]
            chunk_timeout = min(timeout // 3, 300)  # Chia timeout cho t·ª´ng chunk
            
            print(f"üîÑ X·ª≠ l√Ω chunk {i//chunk_size + 1}: {len(chunk)} m√£ (timeout: {chunk_timeout}s)")
            
            chunk_results = _process_stock_chunk(
                chunk, min_gti_score, min_combined_score, 
                max_workers, chunk_timeout
            )
            
            results.extend(chunk_results['results'])
            errors.extend(chunk_results['errors'])
            processed_count += chunk_results['processed']
            
            # Check if we're running out of time
            elapsed = time.time() - start_time
            if elapsed > timeout * 0.8:  # 80% of total timeout
                print(f"‚ö†Ô∏è ƒê√£ s·ª≠ d·ª•ng 80% th·ªùi gian, d·ª´ng scan ƒë·ªÉ tr√°nh timeout")
                break
    else:
        # Normal processing for smaller lists
        chunk_results = _process_stock_chunk(
            stock_list, min_gti_score, min_combined_score,
            max_workers, timeout
        )
        results = chunk_results['results']
        errors = chunk_results['errors']
        processed_count = chunk_results['processed']
    
    # S·∫Øp x·∫øp k·∫øt qu·∫£ theo ƒëi·ªÉm gi·∫£m d·∫ßn
    results.sort(key=lambda x: x['combined_score'], reverse=True)
    
    # Th·ªëng k√™
    execution_time = time.time() - start_time
    success_count = len(results)
    error_count = len(errors)
    total_stocks = len(stock_list)
    
    print(f"\nüìä K·∫æT QU·∫¢ QU√âT TH·ªä TR∆Ø·ªúNG:")
    print(f"   ‚è±Ô∏è  Th·ªùi gian: {execution_time:.1f}s")
    print(f"   ‚úÖ X·ª≠ l√Ω: {processed_count}/{total_stocks}")
    print(f"   üéØ ƒê·∫°t ti√™u ch√≠: {success_count} m√£")
    print(f"   ‚ùå L·ªói: {error_count}")
    
    return {
        "scan_results": results,
        "statistics": {
            "total_scanned": total_stocks,
            "processed_count": processed_count,
            "success_count": success_count,
            "qualified_count": len(results),
            "error_count": error_count,
            "execution_time_seconds": round(execution_time, 2),
            "scan_criteria": {
                "min_gti_score": min_gti_score,
                "min_combined_score": min_combined_score
            },
            "performance_config": {
                "max_workers": max_workers,
                "timeout_used": timeout,
                "chunked_processing": len(stock_list) > GTIConfig.CHUNK_SIZE_FOR_LARGE_SCANS
            }
        },
        "errors": errors,
        "scan_timestamp": datetime.now().isoformat()
    }

def _process_stock_chunk(stock_list: list, min_gti_score: int, min_combined_score: int,
                        max_workers: int, timeout: int):
    """
    üîß X·ª≠ l√Ω m·ªôt chunk stocks v·ªõi timeout handling t·ªët h∆°n
    """
    results = []
    errors = []
    processed = 0
    
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # T·∫°o futures cho t·∫•t c·∫£ m√£ trong chunk
            future_to_stock = {
                executor.submit(scan_single_stock, stock, min_gti_score, min_combined_score): stock 
                for stock in stock_list
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£ v·ªõi timeout per stock
            for future in concurrent.futures.as_completed(future_to_stock, timeout=timeout):
                stock = future_to_stock[future]
                processed += 1
                
                try:
                    result = future.result(timeout=GTIConfig.SINGLE_STOCK_TIMEOUT)
                    if result is not None:
                        results.append(result)
                        print(f"‚úÖ {stock}: T·ªïng ƒëi·ªÉm {result['combined_score']}")
                    else:
                        print(f"‚è≠Ô∏è  {stock}: Kh√¥ng ƒë·∫°t ti√™u ch√≠")
                except Exception as e:
                    error_msg = f"{stock}: {str(e)}"
                    errors.append(error_msg)
                    print(f"‚ùå {error_msg}")
    
    except concurrent.futures.TimeoutError:
        print(f"‚è∞ Chunk timeout sau {timeout} gi√¢y! ƒê√£ x·ª≠ l√Ω {processed}/{len(stock_list)}")
    
    return {
        "results": results,
        "errors": errors,
        "processed": processed
    }

def market_scan_by_category(category: str = "vn30", 
                           min_gti_score: int = 2, 
                           min_combined_score: int = 3):
    """
    üéØ Qu√©t th·ªã tr∆∞·ªùng theo danh m·ª•c c·ª• th·ªÉ
    
    Args:
        category: Lo·∫°i danh s√°ch (vn30, top100, popular, ho·∫∑c t√™n ng√†nh)
        min_gti_score: ƒêi·ªÉm GTI t·ªëi thi·ªÉu
        min_combined_score: ƒêi·ªÉm t·ªïng h·ª£p t·ªëi thi·ªÉu
    
    Returns:
        K·∫øt qu·∫£ scan v·ªõi th√¥ng tin danh m·ª•c
    """
    print(f"üîç Qu√©t th·ªã tr∆∞·ªùng theo danh m·ª•c: {category.upper()}")
    
    # L·∫•y danh s√°ch m√£ theo danh m·ª•c
    stock_list = GTIConfig.get_stock_list_by_type(category)
    
    if not stock_list:
        return {
            "error": f"Kh√¥ng t√¨m th·∫•y danh m·ª•c {category}",
            "available_categories": ["vn30", "top100", "popular"] + list(GTIConfig.SECTOR_STOCKS.keys())
        }
    
    print(f"üìã Danh s√°ch: {len(stock_list)} m√£ c·ªï phi·∫øu")
    
    # Th·ª±c hi·ªán scan
    scan_result = market_scan_parallel(
        stock_list=stock_list,
        min_gti_score=min_gti_score,
        min_combined_score=min_combined_score,
        max_workers=GTIConfig.MARKET_SCAN_BATCH_SIZE,
        timeout=GTIConfig.MARKET_SCAN_TIMEOUT
    )
    
    # Th√™m th√¥ng tin danh m·ª•c
    scan_result["category_info"] = {
        "category_name": category,
        "category_stocks": stock_list,
        "category_size": len(stock_list)
    }
    
    return scan_result

def market_scan_top_picks(limit: int = 20, quick_mode: bool = None):
    """
    üèÜ Qu√©t v√† tr·∫£ v·ªÅ TOP m√£ c·ªï phi·∫øu t·ªët nh·∫•t to√†n th·ªã tr∆∞·ªùng - SECTOR-BASED v3.0
    
    Args:
        limit: S·ªë l∆∞·ª£ng m√£ top c·∫ßn tr·∫£ v·ªÅ
        quick_mode: Ch·∫ø ƒë·ªô nhanh (auto-detect t·ª´ config n·∫øu None)
    
    Returns:
        Top picks v·ªõi ph√¢n t√≠ch chi ti·∫øt
    """
    if quick_mode is None:
        quick_mode = GTIConfig.TOP_PICKS_QUICK_MODE
    
    print(f"üèÜ T√¨m ki·∫øm TOP {limit} m√£ c·ªï phi·∫øu t·ªët nh·∫•t b·∫±ng SECTOR-BASED approach...")
    if quick_mode:
        print("‚ö° S·ª≠ d·ª•ng QUICK MODE - qu√©t √≠t m√£ t·ª´ m·ªói sector")
    
    # Quick mode: Scan 10 m√£ ƒë·∫ßu t·ª´ m·ªói sector (t·ªïng ~100 m√£)
    if quick_mode:
        # Stage 1: Scan VN30 + Popular tr∆∞·ªõc
        priority_stocks = list(set(GTIConfig.VN30_STOCKS + GTIConfig.POPULAR_STOCKS))
        print(f"üéØ Stage 1: Qu√©t {len(priority_stocks)} m√£ ∆∞u ti√™n...")
        
        stage1_result = market_scan_parallel(
            stock_list=priority_stocks,
            min_gti_score=1,
            min_combined_score=1,
            max_workers=GTIConfig.MARKET_SCAN_BATCH_SIZE,
            timeout=120  # 2 ph√∫t cho stage 1
        )
        
        # N·∫øu ƒë√£ c√≥ ƒë·ªß k·∫øt qu·∫£ ch·∫•t l∆∞·ª£ng cao, return lu√¥n
        high_quality_results = [
            stock for stock in stage1_result["scan_results"] 
            if stock["combined_score"] >= 4
        ]
        
        if len(high_quality_results) >= limit:
            print(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(high_quality_results)} m√£ ch·∫•t l∆∞·ª£ng cao t·ª´ stage 1")
            top_picks = high_quality_results[:limit]
            combined_stats = stage1_result["statistics"]
            combined_stats["quick_mode_used"] = True
            combined_stats["scan_method"] = "priority_only"
        else:
            # Stage 2: Scan top 10 t·ª´ m·ªói sector
            sector_stocks = GTIConfig.get_all_sectors_combined(limit_per_sector=10)
            remaining_stocks = [
                stock for stock in sector_stocks 
                if stock not in priority_stocks
            ]
            
            needed = limit - len(high_quality_results)
            print(f"üîÑ Stage 2: C·∫ßn th√™m {needed} m√£, qu√©t top 10 t·ª´ {len(GTIConfig.SECTOR_STOCKS)} sectors...")
            
            stage2_result = market_scan_parallel(
                stock_list=remaining_stocks,
                min_gti_score=1,
                min_combined_score=1,
                max_workers=GTIConfig.MARKET_SCAN_BATCH_SIZE,
                timeout=240  # 4 ph√∫t cho stage 2
            )
            
            # Combine results
            all_results = stage1_result["scan_results"] + stage2_result["scan_results"]
            all_results.sort(key=lambda x: x['combined_score'], reverse=True)
            top_picks = all_results[:limit]
            
            # Combine statistics
            combined_stats = {
                "total_scanned": stage1_result["statistics"]["total_scanned"] + stage2_result["statistics"]["total_scanned"],
                "processed_count": stage1_result["statistics"]["processed_count"] + stage2_result["statistics"]["processed_count"],
                "success_count": len(all_results),
                "qualified_count": len(all_results),
                "error_count": stage1_result["statistics"]["error_count"] + stage2_result["statistics"]["error_count"],
                "execution_time_seconds": stage1_result["statistics"]["execution_time_seconds"] + stage2_result["statistics"]["execution_time_seconds"],
                "quick_mode_used": True,
                "scan_method": "sector_based_limited",
                "stages": {
                    "stage1": stage1_result["statistics"],
                    "stage2": stage2_result["statistics"]
                }
            }
    else:
        # Normal mode: Scan nhi·ªÅu h∆°n t·ª´ c√°c sectors
        print("üîç S·ª≠ d·ª•ng NORMAL MODE - qu√©t nhi·ªÅu h∆°n t·ª´ c√°c sectors")
        sector_stocks = GTIConfig.get_all_sectors_combined(limit_per_sector=20)  # Top 20 t·ª´ m·ªói sector
        
        print(f"üìä S·∫Ω qu√©t {len(sector_stocks)} m√£ t·ª´ {len(GTIConfig.SECTOR_STOCKS)} sectors")
        
        scan_result = market_scan_parallel(
            stock_list=sector_stocks,
            min_gti_score=1,
            min_combined_score=1,
            max_workers=GTIConfig.MARKET_SCAN_BATCH_SIZE,
            timeout=GTIConfig.MARKET_SCAN_TIMEOUT
        )
        
        if not scan_result["scan_results"]:
            return {
                "message": "Kh√¥ng t√¨m th·∫•y m√£ n√†o ƒë·∫°t ti√™u ch√≠ c∆° b·∫£n",
                "scan_info": scan_result["statistics"]
            }
        
        top_picks = scan_result["scan_results"][:limit]
        combined_stats = scan_result["statistics"]
        combined_stats["quick_mode_used"] = False
        combined_stats["scan_method"] = "sector_based_full"
    
    # Ph√¢n lo·∫°i theo m·ª©c ƒë·ªô
    categorized_picks = {
        "very_strong": [stock for stock in top_picks if stock["combined_score"] >= 6],
        "strong": [stock for stock in top_picks if 4 <= stock["combined_score"] < 6],
        "moderate": [stock for stock in top_picks if 2 <= stock["combined_score"] < 4],
        "weak_but_potential": [stock for stock in top_picks if stock["combined_score"] < 2]
    }
    
    # Th·ªëng k√™ theo ng√†nh
    sector_distribution = {}
    for stock in top_picks:
        symbol = stock["stock_symbol"]
        for sector, stocks in GTIConfig.SECTOR_STOCKS.items():
            if symbol in stocks:
                if sector not in sector_distribution:
                    sector_distribution[sector] = []
                sector_distribution[sector].append(symbol)
                break
    
    return {
        "top_picks": top_picks,
        "categorized_picks": categorized_picks,
        "sector_distribution": sector_distribution,
        "summary": {
            "total_found": len(top_picks) if quick_mode else len(scan_result["scan_results"]),
            "top_returned": len(top_picks),
            "very_strong_count": len(categorized_picks["very_strong"]),
            "strong_count": len(categorized_picks["strong"]),
            "moderate_count": len(categorized_picks["moderate"])
        },
        "scan_info": combined_stats,
        "recommendation": get_market_scan_recommendation(top_picks),
        "scan_timestamp": datetime.now().isoformat()
    }

def get_market_scan_recommendation(top_picks: list) -> dict:
    """
    üìã ƒê∆∞a ra khuy·∫øn ngh·ªã d·ª±a tr√™n k·∫øt qu·∫£ market scan
    """
    if not top_picks:
        return {
            "status": "bearish",
            "message": "Th·ªã tr∆∞·ªùng kh√¥ng c√≥ c∆° h·ªôi t·ªët, n√™n th·∫≠n tr·ªçng",
            "action": "WAIT"
        }
    
    very_strong = len([s for s in top_picks if s["combined_score"] >= 6])
    strong = len([s for s in top_picks if 4 <= s["combined_score"] < 6])
    
    if very_strong >= 3:
        return {
            "status": "very_bullish",
            "message": f"Th·ªã tr∆∞·ªùng r·∫•t t√≠ch c·ª±c v·ªõi {very_strong} m√£ r·∫•t m·∫°nh",
            "action": "AGGRESSIVE_BUY",
            "max_position_per_stock": "8-10%",
            "total_portfolio_allocation": "80-90%"
        }
    elif strong >= 5:
        return {
            "status": "bullish", 
            "message": f"Th·ªã tr∆∞·ªùng t√≠ch c·ª±c v·ªõi {strong} m√£ m·∫°nh",
            "action": "SELECTIVE_BUY",
            "max_position_per_stock": "5-7%",
            "total_portfolio_allocation": "60-70%"
        }
    elif len(top_picks) >= 10:
        return {
            "status": "neutral_positive",
            "message": "Th·ªã tr∆∞·ªùng c√≥ c∆° h·ªôi nh∆∞ng c·∫ßn ch·ªçn l·ªçc",
            "action": "CAREFUL_BUY",
            "max_position_per_stock": "3-5%", 
            "total_portfolio_allocation": "40-50%"
        }
    else:
        return {
            "status": "neutral",
            "message": "Th·ªã tr∆∞·ªùng √≠t c∆° h·ªôi, n√™n ƒë·ª£i th·ªùi ƒëi·ªÉm t·ªët h∆°n",
            "action": "WAIT",
            "max_position_per_stock": "2-3%",
            "total_portfolio_allocation": "20-30%"
        }

# ƒêo·∫°n m√£ ƒë·ªÉ ch·∫°y th·ª≠
if __name__ == "__main__":
    ma_can_kiem_tra = "FPT"
    
    print("üöÄ CH·∫†Y TH·ª¨ COMPREHENSIVE GTI ANALYSIS v2.0")
    print("="*50)
    
    # Test comprehensive analysis
    ket_qua_comprehensive = comprehensive_gti_analysis(ma_can_kiem_tra)
    
    if ket_qua_comprehensive['status'] == 'success':
        print(f"\nüìä K·∫æT QU·∫¢ COMPREHENSIVE CHO {ma_can_kiem_tra}:")
        print(f"GTI Score: {ket_qua_comprehensive['gti_analysis']['gti_score']}/4")
        print(f"Pattern Score: {ket_qua_comprehensive['pattern_analysis']['pattern_summary']}")
        print(f"Combined Score: {ket_qua_comprehensive['combined_analysis']['total_score']}")
        print(f"Recommendation: {ket_qua_comprehensive['combined_analysis']['final_recommendation']['emoji']} {ket_qua_comprehensive['combined_analysis']['final_recommendation']['level']}")
        
        print(f"\nüì∞ NEWS SEARCH CONTEXT:")
        print(ket_qua_comprehensive['news_search_context']['search_instruction'])
    else:
        print(f"‚ùå L·ªói: {ket_qua_comprehensive['message']}")
        
        # Fallback to old method
        print("\nüîÑ Ch·∫°y ph√¢n t√≠ch c≈©...")
        du_lieu = lay_du_lieu_co_phieu_vnstock(
            ma_co_phieu=ma_can_kiem_tra,
            start_date="2024-01-01",
            end_date="2025-06-28"
        )

        if du_lieu is not None:
            print(f"ƒê√£ l·∫•y ƒë∆∞·ª£c {len(du_lieu)} b·∫£n ghi cho m√£ {ma_can_kiem_tra}.")
            
            du_lieu_phan_tich = tinh_toan_chi_bao_ky_thuat(du_lieu)
            latest = du_lieu_phan_tich.iloc[-1]
            print(f"\nK·∫øt qu·∫£ c∆° b·∫£n:")
            print(f"Gi√° ƒë√≥ng c·ª≠a: {latest['close']:,.0f} VND")
            print(f"GTI Score: {latest['gti_score']}/4")
            print(f"GTI Signal: {latest['gti_signal']}")
        else:
            print("Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu. Vui l√≤ng:")
            print("1. Ki·ªÉm tra k·∫øt n·ªëi internet")
            print("2. C√†i ƒë·∫∑t vnstock: pip install vnstock")
            print("3. C√†i ƒë·∫∑t ta: pip install ta")
            print("4. Th·ª≠ l·∫°i v·ªõi m√£ c·ªï phi·∫øu kh√°c")