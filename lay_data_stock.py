# Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
try:
    from vnstock import Vnstock
    print("ƒê√£ import th√†nh c√¥ng th∆∞ vi·ªán vnstock")
except ImportError:
    print("Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán vnstock. Vui l√≤ng ch·∫°y: pip install vnstock")
    import sys
    sys.exit(1)

try:
    import ta
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    print("ƒê√£ import th√†nh c√¥ng th∆∞ vi·ªán ta, pandas, numpy v√† datetime")
except ImportError:
    print("Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán ta, pandas ho·∫∑c numpy. Vui l√≤ng ch·∫°y: pip install ta pandas numpy")
    import sys
    sys.exit(1)

def lay_du_lieu_co_phieu_vnstock(ma_co_phieu: str, start_date: str = "2023-01-01", end_date: str = "2024-12-31"):
    """
    H√†m n√†y l·∫•y d·ªØ li·ªáu gi√° l·ªãch s·ª≠ c·ªßa m·ªôt m√£ c·ªï phi·∫øu s·ª≠ d·ª•ng th∆∞ vi·ªán vnstock 3.x.
    
    Args:
        ma_co_phieu (str): M√£ ch·ª©ng kho√°n c·∫ßn l·∫•y, v√≠ d·ª•: "FPT", "HPG".
        start_date (str): Ng√†y b·∫Øt ƒë·∫ßu, ƒë·ªãnh d·∫°ng YYYY-MM-DD
        end_date (str): Ng√†y k·∫øt th√∫c, ƒë·ªãnh d·∫°ng YYYY-MM-DD

    Returns:
        DataFrame ch·ª©a d·ªØ li·ªáu l·ªãch s·ª≠ n·∫øu th√†nh c√¥ng, ho·∫∑c None n·∫øu c√≥ l·ªói.
    """
    print(f"B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu cho m√£: {ma_co_phieu} t·ª´ vnstock")
    print(f"Th·ªùi gian: t·ª´ {start_date} ƒë·∫øn {end_date}")
    
    try:
        # S·ª≠ d·ª•ng API m·ªõi c·ªßa vnstock 3.x
        stock = Vnstock().stock(symbol=ma_co_phieu, source='VCI')
        df = stock.quote.history(start=start_date, end=end_date, interval='1D')
        
        if df is not None and not df.empty:
            print("L·∫•y d·ªØ li·ªáu th√†nh c√¥ng!")
            return df
        else:
            print(f"Kh√¥ng c√≥ d·ªØ li·ªáu cho m√£ {ma_co_phieu} trong kho·∫£ng th·ªùi gian y√™u c·∫ßu.")
            return None
            
    except Exception as e:
        print(f"L·ªói khi l·∫•y d·ªØ li·ªáu: {e}")
        print("C√≥ th·ªÉ th·ª≠ l·∫°i sau ho·∫∑c ki·ªÉm tra l·∫°i m√£ c·ªï phi·∫øu")
        return None

def tinh_toan_chi_bao_ky_thuat(df: pd.DataFrame):
    """
    H√†m n√†y nh·∫≠n v√†o m·ªôt DataFrame v√† t√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t theo h·ªá th·ªëng GTI.
    """
    print("\nB·∫Øt ƒë·∫ßu t√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t theo h·ªá th·ªëng GTI...")
    
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # 1. C√°c ƒë∆∞·ªùng EMA theo h·ªá th·ªëng GTI
    df['EMA10'] = ta.trend.EMAIndicator(df['close'], window=10).ema_indicator()
    df['EMA20'] = ta.trend.EMAIndicator(df['close'], window=20).ema_indicator()
    df['EMA50'] = ta.trend.EMAIndicator(df['close'], window=50).ema_indicator()
    df['EMA200'] = ta.trend.EMAIndicator(df['close'], window=200).ema_indicator()
    
    # 2. T√≠nh to√°n kh·ªëi l∆∞·ª£ng trung b√¨nh 20 phi√™n
    df['volume_avg_20'] = df['volume'].rolling(window=20).mean()
    
    # 3. T√≠nh to√°n ƒë·ªânh 1 nƒÉm (252 phi√™n giao d·ªãch)
    df['high_1_year'] = df['high'].rolling(window=252, min_periods=1).max()
    
    # 4. GTI Trend Check: EMA10 > EMA20 v√† price > EMA10 > EMA20
    df['gti_trend_check'] = (
        (df['EMA10'] > df['EMA20']) & 
        (df['close'] > df['EMA10']) & 
        (df['close'] > df['EMA20'])
    )
    
    # 5. GTI Recent Breakout: Volume > 1.5x trung b√¨nh v√† gi√° tƒÉng m·∫°nh
    # Ki·ªÉm tra trong 5 phi√™n g·∫ßn nh·∫•t c√≥ breakout kh√¥ng
    df['volume_breakout'] = df['volume'] > (df['volume_avg_20'] * 1.5)
    df['price_increase'] = (df['close'] - df['close'].shift(1)) / df['close'].shift(1) > 0.03  # TƒÉng > 3%
    df['daily_breakout'] = df['volume_breakout'] & df['price_increase']
    df['gti_recent_breakout'] = df['daily_breakout'].rolling(window=5).max().fillna(False).astype(bool)
    
    # 6. GTI Distance to High: Kho·∫£ng c√°ch ƒë·∫øn ƒë·ªânh 1 nƒÉm (%)
    df['gti_dist_to_high_percent'] = ((df['high_1_year'] - df['close']) / df['close'] * 100).round(2)
    
    # 7. GTI Pullback Check: Gi√° g·∫ßn EMA10 ho·∫∑c EMA20 (trong v√≤ng 2%)
    df['distance_to_ema10_percent'] = abs((df['close'] - df['EMA10']) / df['EMA10'] * 100)
    df['distance_to_ema20_percent'] = abs((df['close'] - df['EMA20']) / df['EMA20'] * 100)
    df['gti_is_pullback'] = (
        (df['distance_to_ema10_percent'] <= 2.0) | 
        (df['distance_to_ema20_percent'] <= 2.0)
    )
    
    # 8. C√°c ch·ªâ b√°o k·ªπ thu·∫≠t truy·ªÅn th·ªëng (gi·ªØ l·∫°i cho tham kh·∫£o)
    df['RSI'] = ta.momentum.RSIIndicator(df['close']).rsi()
    macd = ta.trend.MACD(df['close'])
    df['MACD'] = macd.macd()
    df['MACD_signal'] = macd.macd_signal()
    df['SMA_20'] = ta.trend.SMAIndicator(df['close'], window=20).sma_indicator()
    
    # 9. GTI Overall Score: T·ªïng ƒëi·ªÉm GTI (0-4)
    df['gti_score'] = (
        df['gti_trend_check'].astype(int) +
        df['gti_recent_breakout'].astype(int) +
        (df['gti_dist_to_high_percent'] <= 15).astype(int) +  # G·∫ßn ƒë·ªânh (c√°ch < 15%)
        df['gti_is_pullback'].astype(int)
    )
    
    # 10. GTI Signal: T√≠n hi·ªáu mua/b√°n theo GTI
    df['gti_signal'] = 'HOLD'
    df.loc[df['gti_score'] >= 3, 'gti_signal'] = 'BUY'
    df.loc[df['gti_score'] <= 1, 'gti_signal'] = 'AVOID'
    
    print("T√≠nh to√°n c√°c ch·ªâ b√°o GTI ho√†n t·∫•t!")
    return df

def detect_free_patterns(df: pd.DataFrame):
    """
    H√†m mi·ªÖn ph√≠ ƒë·ªÉ detect c√°c patterns ph·ªï bi·∫øn - kh√¥ng c·∫ßn th∆∞ vi·ªán tr·∫£ ph√≠
    Ho√†n to√†n t·ª± code d·ª±a tr√™n logic OHLC
    """
    print("\nB·∫Øt ƒë·∫ßu ph√°t hi·ªán patterns mi·ªÖn ph√≠...")
    
    # T·∫°o b·∫£n sao
    df = df.copy()
    
    # T√≠nh to√°n c√°c gi√° tr·ªã c∆° b·∫£n
    df['body_size'] = abs(df['close'] - df['open'])
    df['total_range'] = df['high'] - df['low']
    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)
    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']
    df['is_bullish'] = df['close'] > df['open']
    df['is_bearish'] = df['close'] < df['open']
    
    # 1. DOJI PATTERN (n·∫øn doji - open ‚âà close)
    df['pattern_doji'] = (df['body_size'] / df['total_range']) < 0.1
    
    # 2. HAMMER PATTERN (n·∫øn b√∫a - shadow d∆∞·ªõi d√†i)
    df['pattern_hammer'] = (
        (df['lower_shadow'] > 2 * df['body_size']) & 
        (df['upper_shadow'] < df['body_size']) &
        (df['total_range'] > 0)  # Tr√°nh chia cho 0
    )
    
    # 3. HANGING MAN (n·∫øn treo c·ªï - gi·ªëng hammer nh∆∞ng ·ªü ƒë·ªânh)
    df['pattern_hanging_man'] = (
        df['pattern_hammer'] & 
        (df['close'] < df['close'].shift(1))  # Gi√° gi·∫£m so v·ªõi phi√™n tr∆∞·ªõc
    )
    
    # 4. BULLISH ENGULFING (n·∫øn bao ph·ªß tƒÉng)
    prev_bearish = df['is_bearish'].shift(1)
    curr_bullish = df['is_bullish']
    engulfs = (df['open'] <= df['close'].shift(1)) & (df['close'] >= df['open'].shift(1))
    df['pattern_bullish_engulfing'] = prev_bearish & curr_bullish & engulfs
    
    # 5. BEARISH ENGULFING (n·∫øn bao ph·ªß gi·∫£m)
    prev_bullish = df['is_bullish'].shift(1)
    curr_bearish = df['is_bearish']
    engulfs_bear = (df['open'] >= df['close'].shift(1)) & (df['close'] <= df['open'].shift(1))
    df['pattern_bearish_engulfing'] = prev_bullish & curr_bearish & engulfs_bear
    
    # 6. MORNING STAR (sao mai - 3 n·∫øn)
    # N·∫øn 1: bearish, N·∫øn 2: doji/small body, N·∫øn 3: bullish
    cond1 = df['is_bearish'].shift(2)  # N·∫øn 1 gi·∫£m
    cond2 = (df['body_size'].shift(1) / df['total_range'].shift(1)) < 0.3  # N·∫øn 2 th√¢n nh·ªè
    cond3 = df['is_bullish']  # N·∫øn 3 tƒÉng
    cond4 = df['close'] > df['close'].shift(2)  # N·∫øn 3 cao h∆°n n·∫øn 1
    df['pattern_morning_star'] = cond1 & cond2 & cond3 & cond4
    
    # 7. EVENING STAR (sao h√¥m - 3 n·∫øn)
    cond1_eve = df['is_bullish'].shift(2)  # N·∫øn 1 tƒÉng
    cond2_eve = (df['body_size'].shift(1) / df['total_range'].shift(1)) < 0.3  # N·∫øn 2 th√¢n nh·ªè
    cond3_eve = df['is_bearish']  # N·∫øn 3 gi·∫£m
    cond4_eve = df['close'] < df['close'].shift(2)  # N·∫øn 3 th·∫•p h∆°n n·∫øn 1
    df['pattern_evening_star'] = cond1_eve & cond2_eve & cond3_eve & cond4_eve
    
    # 8. SUPPORT/RESISTANCE LEVELS (ƒë∆°n gi·∫£n)
    window = 20
    df['resistance_level'] = df['high'].rolling(window=window).max().shift(1)
    df['support_level'] = df['low'].rolling(window=window).min().shift(1)
    
    # 9. BREAKOUT PATTERNS
    df['pattern_resistance_breakout'] = (
        (df['close'] > df['resistance_level']) & 
        (df['volume'] > df['volume'].rolling(window=20).mean() * 1.2)  # Volume cao
    )
    
    df['pattern_support_breakdown'] = (
        (df['close'] < df['support_level']) & 
        (df['volume'] > df['volume'].rolling(window=20).mean() * 1.2)  # Volume cao
    )
    
    # 10. VOLUME SPIKE PATTERN
    df['volume_avg_20'] = df['volume'].rolling(window=20).mean()
    df['pattern_volume_spike'] = df['volume'] > (df['volume_avg_20'] * 2)
    
    # 11. GAP PATTERNS
    df['gap_up'] = df['low'] > df['high'].shift(1)
    df['gap_down'] = df['high'] < df['low'].shift(1)
    df['pattern_gap_up'] = df['gap_up'] & df['is_bullish']
    df['pattern_gap_down'] = df['gap_down'] & df['is_bearish']
    
    # 12. SIMPLE TREND PATTERNS
    df['trend_5d'] = df['close'].rolling(5).apply(lambda x: 1 if x.iloc[-1] > x.iloc[0] else 0)
    df['pattern_strong_uptrend'] = (
        (df['trend_5d'] == 1) & 
        (df['close'] > df['close'].rolling(10).mean()) &
        (df['volume'] > df['volume_avg_20'])
    )
    
    print("Ph√°t hi·ªán patterns mi·ªÖn ph√≠ ho√†n t·∫•t!")
    return df

def phan_tich_pattern_results(df: pd.DataFrame, ma_co_phieu: str):
    """
    Ph√¢n t√≠ch k·∫øt qu·∫£ patterns v√† ƒë∆∞a ra b√°o c√°o
    """
    print(f"\nüìä B√ÅO C√ÅO PATTERNS CHO M√É {ma_co_phieu}")
    print("="*50)
    
    # L·∫•y d·ªØ li·ªáu 10 phi√™n g·∫ßn nh·∫•t
    recent_data = df.tail(10)
    latest = df.iloc[-1]
    
    # ƒê·∫øm patterns trong 10 phi√™n g·∫ßn nh·∫•t
    pattern_columns = [col for col in df.columns if col.startswith('pattern_')]
    
    print("üîç PATTERNS PH√ÅT HI·ªÜN TRONG 10 PHI√äN G·∫¶N NH·∫§T:")
    for pattern in pattern_columns:
        count = recent_data[pattern].sum()
        if count > 0:
            pattern_name = pattern.replace('pattern_', '').replace('_', ' ').title()
            print(f"   ‚úÖ {pattern_name}: {count} l·∫ßn")
    
    print(f"\nüìà TH√îNG TIN PHI√äN G·∫¶N NH·∫§T ({latest.name}):")
    print(f"   Gi√° ƒë√≥ng c·ª≠a: {latest['close']:,.0f} VND")
    print(f"   Kh·ªëi l∆∞·ª£ng: {latest['volume']:,.0f}")
    print(f"   Support level: {latest['support_level']:,.0f} VND")
    print(f"   Resistance level: {latest['resistance_level']:,.0f} VND")
    
    print(f"\nüéØ PATTERNS HI·ªÜN T·∫†I:")
    current_patterns = []
    for pattern in pattern_columns:
        if latest[pattern]:
            pattern_name = pattern.replace('pattern_', '').replace('_', ' ').title()
            current_patterns.append(pattern_name)
    
    if current_patterns:
        for p in current_patterns:
            print(f"   üî• {p}")
    else:
        print("   ‚û°Ô∏è  Kh√¥ng c√≥ pattern ƒë·∫∑c bi·ªát")
    
    # T√≠nh ƒëi·ªÉm pattern t·ªïng h·ª£p (bao g·ªìm c·∫£ large patterns)
    bullish_patterns = ['bullish_engulfing', 'morning_star', 'hammer', 'resistance_breakout', 'gap_up', 'strong_uptrend']
    bearish_patterns = ['bearish_engulfing', 'evening_star', 'hanging_man', 'support_breakdown', 'gap_down']
    
    # Th√™m large patterns (c√≥ ƒëi·ªÉm cao h∆°n do quan tr·ªçng h∆°n)
    large_bullish_patterns = ['cup_handle', 'bull_flag', 'base_n_break', 'ascending_triangle']
    
    # ƒêi·ªÉm cho patterns th∆∞·ªùng
    bullish_score = sum([latest[f'pattern_{p}'] for p in bullish_patterns if f'pattern_{p}' in df.columns])
    bearish_score = sum([latest[f'pattern_{p}'] for p in bearish_patterns if f'pattern_{p}' in df.columns])
    
    # ƒêi·ªÉm cho large patterns (x2 do quan tr·ªçng h∆°n)
    large_bullish_score = sum([latest[f'pattern_{p}'] * 2 for p in large_bullish_patterns if f'pattern_{p}' in df.columns])
    
    # T·ªïng ƒëi·ªÉm bullish
    bullish_score += large_bullish_score
    
    print(f"\n‚öñÔ∏è  ƒêI·ªÇM PATTERN T·ªîNG H·ª¢P:")
    print(f"   Bullish Score: {bullish_score}")
    print(f"   Bearish Score: {bearish_score}")
    
    if bullish_score > bearish_score:
        print(f"   üìà Xu h∆∞·ªõng: T√çCH C·ª∞C")
    elif bearish_score > bullish_score:
        print(f"   üìâ Xu h∆∞·ªõng: TI√äU C·ª∞C") 
    else:
        print(f"   ‚û°Ô∏è  Xu h∆∞·ªõng: TRUNG T√çNH")
    
    return {
        'bullish_score': bullish_score,
        'bearish_score': bearish_score,
        'current_patterns': current_patterns,
        'latest_data': latest
    }

def detect_large_chart_patterns(df: pd.DataFrame, lookback_window: int = 60):
    """
    üîç Ph√°t hi·ªán c√°c m·∫´u h√¨nh l·ªõn (Large Chart Patterns)
    - Cup & Handle
    - Bull Flag / Bear Flag  
    - Base n' Break
    - Ascending/Descending Triangle
    """
    print("\nüîç B·∫Øt ƒë·∫ßu ph√°t hi·ªán m·∫´u h√¨nh l·ªõn...")
    
    df = df.copy()
    
    # T√≠nh to√°n rolling max/min cho pattern detection
    df['rolling_high_20'] = df['high'].rolling(window=20).max()
    df['rolling_low_20'] = df['low'].rolling(window=20).min()
    df['rolling_high_60'] = df['high'].rolling(window=60).max()
    df['rolling_low_60'] = df['low'].rolling(window=60).min()
    
    # 1. CUP & HANDLE PATTERN
    def detect_cup_and_handle(df_local, window=50):
        """Ph√°t hi·ªán m·∫´u h√¨nh Cup & Handle"""
        patterns = []
        
        for i in range(window, len(df_local) - 10):
            # L·∫•y d·ªØ li·ªáu trong window
            data_window = df_local.iloc[i-window:i+10]
            
            # T√¨m 2 ƒë·ªânh cao nh·∫•t (left rim, right rim)
            high_peaks = data_window['high'].nlargest(3)
            
            if len(high_peaks) >= 2:
                # Cup: c√≥ ƒë√°y s√¢u gi·ªØa 2 ƒë·ªânh
                left_peak = high_peaks.iloc[0]
                right_peak = high_peaks.iloc[1]
                
                # Cup depth should be 12-33% of left peak
                cup_depth_ratio = (left_peak - data_window['low'].min()) / left_peak
                
                if 0.12 <= cup_depth_ratio <= 0.33:
                    # Handle: pullback < 50% of cup depth
                    handle_start = i
                    recent_data = df_local.iloc[handle_start:handle_start+10]
                    
                    if len(recent_data) > 5:
                        handle_depth = (recent_data['high'].max() - recent_data['low'].min()) / recent_data['high'].max()
                        
                        if handle_depth < (cup_depth_ratio * 0.5):
                            patterns.append(i)
        
        return patterns
    
    cup_handle_patterns = detect_cup_and_handle(df)
    df['pattern_cup_handle'] = False
    if cup_handle_patterns:
        for idx in cup_handle_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_cup_handle')] = True
    
    # 2. BULL FLAG PATTERN
    def detect_bull_flag(df_local, window=30):
        """Ph√°t hi·ªán m·∫´u h√¨nh Bull Flag"""
        patterns = []
        
        for i in range(window, len(df_local) - 5):
            # Flagpole: Strong upward move
            flagpole_data = df_local.iloc[i-window:i-10]
            recent_data = df_local.iloc[i-10:i]
            
            # Check for strong upward move (flagpole)
            flagpole_gain = (flagpole_data['close'].iloc[-1] - flagpole_data['close'].iloc[0]) / flagpole_data['close'].iloc[0]
            
            if flagpole_gain > 0.15:  # At least 15% gain
                # Flag: slight downward or sideways consolidation
                flag_slope = (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / len(recent_data)
                flag_range = (recent_data['high'].max() - recent_data['low'].min()) / recent_data['close'].mean()
                
                # Flag should be small consolidation
                if -0.08 <= flag_slope <= 0.03 and flag_range < 0.15:
                    # Volume should decrease during flag
                    volume_trend = recent_data['volume'].iloc[-3:].mean() < flagpole_data['volume'].iloc[-3:].mean()
                    if volume_trend:
                        patterns.append(i)
        
        return patterns
    
    bull_flag_patterns = detect_bull_flag(df)
    df['pattern_bull_flag'] = False
    if bull_flag_patterns:
        for idx in bull_flag_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_bull_flag')] = True
    
    # 3. BASE N' BREAK PATTERN
    def detect_base_n_break(df_local, window=40):
        """Ph√°t hi·ªán m·∫´u h√¨nh Base n' Break"""
        patterns = []
        
        for i in range(window, len(df_local) - 3):
            base_data = df_local.iloc[i-window:i]
            
            # Base: tight sideways consolidation
            base_range = (base_data['high'].max() - base_data['low'].min()) / base_data['close'].mean()
            
            # Base should be tight (< 20% range)
            if base_range < 0.20:
                # Check for decreasing volatility in base
                early_base = base_data.iloc[:len(base_data)//2]
                late_base = base_data.iloc[len(base_data)//2:]
                
                early_volatility = (early_base['high'] - early_base['low']).mean() / early_base['close'].mean()
                late_volatility = (late_base['high'] - late_base['low']).mean() / late_base['close'].mean()
                
                # Volatility contraction
                if late_volatility < early_volatility:
                    # Breakout: price breaks above base resistance with volume
                    resistance_level = base_data['high'].max()
                    current_price = df_local.iloc[i]['close']
                    current_volume = df_local.iloc[i]['volume']
                    avg_volume = base_data['volume'].mean()
                    
                    if current_price > resistance_level and current_volume > (avg_volume * 1.5):
                        patterns.append(i)
        
        return patterns
    
    base_break_patterns = detect_base_n_break(df)
    df['pattern_base_n_break'] = False
    if base_break_patterns:
        for idx in base_break_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_base_n_break')] = True
    
    # 4. ASCENDING TRIANGLE
    def detect_ascending_triangle(df_local, window=30):
        """Ph√°t hi·ªán m·∫´u h√¨nh Ascending Triangle"""
        patterns = []
        
        for i in range(window, len(df_local) - 5):
            triangle_data = df_local.iloc[i-window:i]
            
            # Resistance: horizontal line (multiple touches at same level)
            resistance_level = triangle_data['high'].max()
            resistance_touches = len(triangle_data[triangle_data['high'] >= resistance_level * 0.99])
            
            # Support: rising trend line
            lows = triangle_data['low']
            time_index = range(len(lows))
            
            # Simple rising support check
            first_quarter_low = lows.iloc[:len(lows)//4].min()
            last_quarter_low = lows.iloc[-len(lows)//4:].min()
            
            if resistance_touches >= 2 and last_quarter_low > first_quarter_low:
                # Breakout above resistance
                current_price = df_local.iloc[i]['close']
                current_volume = df_local.iloc[i]['volume']
                avg_volume = triangle_data['volume'].mean()
                
                if current_price > resistance_level and current_volume > (avg_volume * 1.3):
                    patterns.append(i)
        
        return patterns
    
    ascending_triangle_patterns = detect_ascending_triangle(df)
    df['pattern_ascending_triangle'] = False
    if ascending_triangle_patterns:
        for idx in ascending_triangle_patterns:
            if idx < len(df):
                df.iloc[idx, df.columns.get_loc('pattern_ascending_triangle')] = True
    
    print("‚úÖ Ho√†n th√†nh ph√°t hi·ªán m·∫´u h√¨nh l·ªõn!")
    return df

def get_market_context():
    """
    üåä L·∫•y b·ªëi c·∫£nh th·ªã tr∆∞·ªùng chung (VNINDEX) theo h·ªá th·ªëng GTI
    """
    print("\nüåä ƒêang ph√¢n t√≠ch b·ªëi c·∫£nh th·ªã tr∆∞·ªùng...")
    
    try:
        # L·∫•y d·ªØ li·ªáu VNINDEX
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        vnindex_df = lay_du_lieu_co_phieu_vnstock("VNINDEX", start_date, end_date)
        
        if vnindex_df is None or vnindex_df.empty:
            return {
                "status": "error",
                "message": "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu VNINDEX"
            }
        
        # T√≠nh to√°n GTI cho VNINDEX
        vnindex_gti = tinh_toan_chi_bao_ky_thuat(vnindex_df)
        latest_vnindex = vnindex_gti.iloc[-1]
        
        # Ph√¢n t√≠ch trend VNINDEX
        vnindex_trend = "UPTREND" if latest_vnindex['gti_trend_check'] else "SIDEWAY/DOWNTREND"
        vnindex_score = int(latest_vnindex['gti_score'])
        
        # ƒê√°nh gi√° hi·ªáu qu·∫£ GTI theo market phase
        if vnindex_trend == "UPTREND" and vnindex_score >= 3:
            effectiveness = "CAO (70-80%)"
            recommendation = "Th√≠ch h·ª£p cho chi·∫øn l∆∞·ª£c t√≠ch c·ª±c"
            max_position = "8-10% NAV per stock"
        elif vnindex_score >= 2:
            effectiveness = "TRUNG B√åNH (50-60%)" 
            recommendation = "Gi·∫£m t·ª∑ tr·ªçng, ch·ªçn l·ªçc k·ªπ"
            max_position = "5-7% NAV per stock"
        else:
            effectiveness = "TH·∫§P (<50%)"
            recommendation = "Tr√°nh xa ho·∫∑c trade v·ªõi ƒëi·ªÉm ‚â•5"
            max_position = "3-5% NAV per stock"
        
        market_context = {
            "status": "success",
            "vnindex": {
                "current_price": round(float(latest_vnindex['close']), 2),
                "gti_score": vnindex_score,
                "trend": vnindex_trend,
                "trend_check": bool(latest_vnindex['gti_trend_check']),
                "recent_breakout": bool(latest_vnindex['gti_recent_breakout']),
                "near_high": bool(latest_vnindex['gti_dist_to_high_percent'] <= 15),
                "dist_to_high": round(float(latest_vnindex['gti_dist_to_high_percent']), 2)
            },
            "gti_effectiveness": {
                "current_market": vnindex_trend,
                "effectiveness_rate": effectiveness,
                "recommendation": recommendation,
                "max_position_size": max_position
            },
            "analysis_note": f"VNINDEX ƒëang ·ªü giai ƒëo·∫°n {vnindex_trend} v·ªõi GTI score {vnindex_score}/4. "
                           f"ƒê·ªô ch√≠nh x√°c h·ªá th·ªëng GTI ∆∞·ªõc t√≠nh: {effectiveness}."
        }
        
        print(f"‚úÖ VNINDEX: {latest_vnindex['close']:.1f} | GTI: {vnindex_score}/4 | Trend: {vnindex_trend}")
        return market_context
        
    except Exception as e:
        print(f"‚ùå L·ªói ph√¢n t√≠ch market context: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch th·ªã tr∆∞·ªùng: {str(e)}"
        }

def get_sector_analysis(stock_symbol: str):
    """
    üè≠ Ph√¢n t√≠ch ch·ªâ s·ªë ng√†nh (ƒë∆°n gi·∫£n ho√° - s·ª≠ d·ª•ng c√°c m√£ ƒë·∫°i di·ªán)
    """
    print(f"\nüè≠ ƒêang ph√¢n t√≠ch ng√†nh cho {stock_symbol}...")
    
    # Mapping m√£ c·ªï phi·∫øu v·ªõi ng√†nh v√† m√£ ƒë·∫°i di·ªán
    sector_mapping = {
        # Banking
        "ACB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "BID": {"sector": "Ng√¢n h√†ng", "representative": "VCB"}, 
        "CTG": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "HDB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "MBB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "STB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "TCB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "TPB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VCB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VPB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        "VIB": {"sector": "Ng√¢n h√†ng", "representative": "VCB"},
        
        # Real Estate
        "VHM": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        "VIC": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        "VRE": {"sector": "B·∫•t ƒë·ªông s·∫£n", "representative": "VIC"},
        
        # Technology
        "FPT": {"sector": "C√¥ng ngh·ªá", "representative": "FPT"},
        
        # Steel
        "HPG": {"sector": "Th√©p", "representative": "HPG"},
        
        # Retail
        "MWG": {"sector": "B√°n l·∫ª", "representative": "MWG"},
        
        # Oil & Gas
        "GAS": {"sector": "D·∫ßu kh√≠", "representative": "GAS"},
        "PLX": {"sector": "D·∫ßu kh√≠", "representative": "GAS"},
        
        # Food & Beverage
        "VNM": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
        "MSN": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
        "SAB": {"sector": "Th·ª±c ph·∫©m", "representative": "VNM"},
    }
    
    sector_info = sector_mapping.get(stock_symbol.upper())
    
    if not sector_info:
        return {
            "status": "unknown_sector",
            "message": f"Ch∆∞a c√≥ th√¥ng tin ng√†nh cho {stock_symbol}"
        }
    
    try:
        # L·∫•y d·ªØ li·ªáu m√£ ƒë·∫°i di·ªán ng√†nh
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        sector_df = lay_du_lieu_co_phieu_vnstock(sector_info["representative"], start_date, end_date)
        
        if sector_df is None or sector_df.empty:
            return {
                "status": "error", 
                "message": f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu ng√†nh {sector_info['sector']}"
            }
        
        # T√≠nh GTI cho ng√†nh
        sector_gti = tinh_toan_chi_bao_ky_thuat(sector_df)
        latest_sector = sector_gti.iloc[-1]
        sector_score = int(latest_sector['gti_score'])
        
        sector_trend = "T√çCH C·ª∞C" if latest_sector['gti_trend_check'] else "TI√äU C·ª∞C"
        
        sector_analysis = {
            "status": "success",
            "sector_name": sector_info["sector"],
            "representative_stock": sector_info["representative"],
            "sector_gti_score": sector_score,
            "sector_trend": sector_trend,
            "sector_price": round(float(latest_sector['close']), 2),
            "analysis_note": f"Ng√†nh {sector_info['sector']} (ƒë·∫°i di·ªán: {sector_info['representative']}) "
                           f"c√≥ GTI score {sector_score}/4, xu h∆∞·ªõng {sector_trend}."
        }
        
        print(f"‚úÖ Ng√†nh {sector_info['sector']}: GTI {sector_score}/4 | {sector_trend}")
        return sector_analysis
        
    except Exception as e:
        print(f"‚ùå L·ªói ph√¢n t√≠ch ng√†nh: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch ng√†nh: {str(e)}"
        }

def prepare_news_search_context(stock_symbol: str, sector_name: str = None):
    """
    üì∞ Chu·∫©n b·ªã context cho ChatGPT search tin t·ª©c
    QUAN TR·ªåNG: Ch·ªâ search tin t·ª©c, s·ª± ki·ªán - KH√îNG search d·ªØ li·ªáu gi√°, volume, ch·ªâ s·ªë k·ªπ thu·∫≠t
    """
    search_contexts = {
        "company_news": f"tin t·ª©c m·ªõi nh·∫•t v·ªÅ c√¥ng ty {stock_symbol} Vi·ªát Nam",
        "earnings_news": f"k·∫øt qu·∫£ kinh doanh {stock_symbol} 2024 2025",
        "industry_events": f"tin t·ª©c ng√†nh {sector_name if sector_name else 'ch·ª©ng kho√°n'} Vi·ªát Nam",
        "policy_updates": f"ch√≠nh s√°ch ·∫£nh h∆∞·ªüng ng√†nh {sector_name if sector_name else 't√†i ch√≠nh'} Vi·ªát Nam"
    }
    
    return {
        "search_instruction": f"""
üîç H∆Ø·ªöNG D·∫™N SEARCH TIN T·ª®C CHO {stock_symbol}:

‚úÖ C·∫¶N T√åM:
- Tin t·ª©c c√¥ng ty: {search_contexts['company_news']}
- K·∫øt qu·∫£ kinh doanh: {search_contexts['earnings_news']}
- S·ª± ki·ªán ng√†nh: {search_contexts['industry_events']}
- Ch√≠nh s√°ch li√™n quan: {search_contexts['policy_updates']}

‚ùå TUY·ªÜT ƒê·ªêI KH√îNG T√åM:
- D·ªØ li·ªáu gi√° c·ªï phi·∫øu, volume, ch·ªâ s·ªë k·ªπ thu·∫≠t
- D·ª± ƒëo√°n gi√°, forecast
- Ph√¢n t√≠ch k·ªπ thu·∫≠t t·ª´ b√™n ngo√†i

üìä L∆ØU √ù: T·∫•t c·∫£ d·ªØ li·ªáu v·ªÅ gi√° v√† ch·ªâ s·ªë k·ªπ thu·∫≠t ƒë√£ ƒë∆∞·ª£c cung c·∫•p qua API.
        """,
        "suggested_searches": list(search_contexts.values())
    }

def comprehensive_gti_analysis(stock_symbol: str, start_date: str = None, end_date: str = None):
    """
    üöÄ Ph√¢n t√≠ch GTI Pro v2.0 TO√ÄN DI·ªÜN:
    1. GTI Core (4 ti√™u ch√≠) + Enhanced Patterns (16 patterns)
    2. Market Context (VNINDEX) + Sector Analysis
    3. News Search Context cho ChatGPT
    4. Combined Scoring & Recommendations
    """
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH GTI PRO v2.0 TO√ÄN DI·ªÜN CHO {stock_symbol}")
    print("="*80)
    
    # T√≠nh to√°n th·ªùi gian m·∫∑c ƒë·ªãnh
    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if not start_date:
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
    
    try:
        # B∆Ø·ªöC 1: L·∫•y d·ªØ li·ªáu c∆° b·∫£n
        print("üìä B∆Ø·ªöC 1: L·∫•y d·ªØ li·ªáu c∆° b·∫£n...")
        df = lay_du_lieu_co_phieu_vnstock(stock_symbol, start_date, end_date)
        
        if df is None or df.empty:
            return {
                "status": "error",
                "message": f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho {stock_symbol}"
            }
        
        # B∆Ø·ªöC 2: GTI Core Analysis
        print("üî• B∆Ø·ªöC 2: Ph√¢n t√≠ch GTI Core...")
        df_gti = tinh_toan_chi_bao_ky_thuat(df)
        
        # B∆Ø·ªöC 3: Basic Pattern Detection
        print("üéØ B∆Ø·ªöC 3: Ph√°t hi·ªán Basic Patterns...")
        df_patterns = detect_free_patterns(df_gti)
        
        # B∆Ø·ªöC 4: Large Chart Patterns  
        print("üìà B∆Ø·ªöC 4: Ph√°t hi·ªán Large Chart Patterns...")
        df_patterns = detect_large_chart_patterns(df_patterns)
        
        # B∆Ø·ªöC 5: Pattern Analysis
        print("üìä B∆Ø·ªöC 5: Ph√¢n t√≠ch Pattern Results...")
        pattern_results = phan_tich_pattern_results(df_patterns, stock_symbol)
        
        # B∆Ø·ªöC 6: Market Context Analysis
        print("üåä B∆Ø·ªöC 6: Ph√¢n t√≠ch Market Context...")
        market_context = get_market_context()
        
        # B∆Ø·ªöC 7: Sector Analysis
        print("üè≠ B∆Ø·ªöC 7: Ph√¢n t√≠ch Sector...")
        sector_analysis = get_sector_analysis(stock_symbol)
        
        # B∆Ø·ªöC 8: News Search Context
        print("üì∞ B∆Ø·ªöC 8: Chu·∫©n b·ªã News Search Context...")
        sector_name = sector_analysis.get('sector_name') if sector_analysis.get('status') == 'success' else None
        news_context = prepare_news_search_context(stock_symbol, sector_name)
        
        # B∆Ø·ªöC 9: Combined Scoring v2.0
        print("‚ö° B∆Ø·ªöC 9: T√≠nh to√°n Enhanced Scoring...")
        latest = df_patterns.iloc[-1]
        
        # GTI Score (0-4)
        gti_score = int(latest['gti_score']) if pd.notna(latest['gti_score']) else 0
        
        # Basic Pattern Scores
        basic_bullish = pattern_results.get('bullish_score', 0)
        basic_bearish = pattern_results.get('bearish_score', 0)
        
        # Large Pattern Scores (√ó2 points)
        large_patterns = ['cup_handle', 'bull_flag', 'base_n_break', 'ascending_triangle']
        large_bullish_score = 0
        for pattern in large_patterns:
            if f'pattern_{pattern}' in df_patterns.columns and latest[f'pattern_{pattern}']:
                large_bullish_score += 2  # Large patterns worth 2 points each
        
        # Base Score: GTI + Basic + Large
        base_score = gti_score + basic_bullish - basic_bearish + large_bullish_score
        
        # Market Context Adjustments
        market_adjustment = 0
        if market_context.get('status') == 'success':
            vnindex_gti = market_context['vnindex']['gti_score']
            if vnindex_gti >= 3:  # VNINDEX uptrend
                market_adjustment += 0.5
            elif vnindex_gti <= 1:  # VNINDEX downtrend
                market_adjustment -= 0.5
        
        # Sector Adjustment
        sector_adjustment = 0
        if sector_analysis.get('status') == 'success':
            if sector_analysis['sector_trend'] == 'T√çCH C·ª∞C':
                sector_adjustment += 0.25
            elif sector_analysis['sector_trend'] == 'TI√äU C·ª∞C':
                sector_adjustment -= 0.25
        
        # Final Combined Score
        combined_score = base_score + market_adjustment + sector_adjustment
        
        # Enhanced Recommendations
        if combined_score >= 6:
            recommendation = {
                "level": "C·ª∞C K·ª≤ T√çCH C·ª∞C", 
                "action": "STRONG BUY",
                "emoji": "üü¢",
                "position_size": "8-12% NAV",
                "message": "C∆° h·ªôi ƒë·∫ßu t∆∞ xu·∫•t s·∫Øc v·ªõi ƒëi·ªÉm s·ªë cao"
            }
        elif combined_score >= 4:
            recommendation = {
                "level": "R·∫§T T√çCH C·ª∞C", 
                "action": "C√ÇN NH·∫ÆC MUA",
                "emoji": "üü¢", 
                "position_size": "5-8% NAV",
                "message": "C∆° h·ªôi t·ªët, c√¢n nh·∫Øc mua v√†o"
            }
        elif combined_score >= 2:
            recommendation = {
                "level": "T√çCH C·ª∞C", 
                "action": "THEO D√ïI",
                "emoji": "üü°",
                "position_size": "3-5% NAV", 
                "message": "Theo d√µi v√† ch·ªù t√≠n hi·ªáu r√µ h∆°n"
            }
        elif combined_score >= 0:
            recommendation = {
                "level": "TRUNG T√çNH", 
                "action": "CH·ªú T√çN HI·ªÜU",
                "emoji": "üü†",
                "position_size": "0-3% NAV",
                "message": "Ch∆∞a c√≥ t√≠n hi·ªáu r√µ r√†ng, ch·ªù ƒë·ª£i"
            }
        else:
            recommendation = {
                "level": "TI√äU C·ª∞C", 
                "action": "TR√ÅNH XA",
                "emoji": "üî¥",
                "position_size": "0% NAV", 
                "message": "Tr√°nh xa ho·∫∑c ch·ªù c·∫£i thi·ªán"
            }
        
        # B∆Ø·ªöC 10: T·∫°o k·∫øt qu·∫£ comprehensive
        result = {
            "status": "success",
            "analysis_date": latest.name.strftime("%Y-%m-%d") if hasattr(latest.name, 'strftime') else str(latest.name),
            "stock_symbol": stock_symbol.upper(),
            "closing_price": round(float(latest['close']), 2),
            
            # GTI Analysis
            "gti_analysis": {
                "gti_score": gti_score,
                "gti_criteria": {
                    "trend_check": bool(latest['gti_trend_check']) if pd.notna(latest['gti_trend_check']) else False,
                    "recent_breakout": bool(latest['gti_recent_breakout']) if pd.notna(latest['gti_recent_breakout']) else False,
                    "near_one_year_high": bool(latest['gti_dist_to_high_percent'] <= 15) if pd.notna(latest['gti_dist_to_high_percent']) else False,
                    "is_pullback": bool(latest['gti_is_pullback']) if pd.notna(latest['gti_is_pullback']) else False
                }
            },
            
            # Enhanced Pattern Analysis
            "pattern_analysis": {
                "basic_bullish_score": basic_bullish,
                "basic_bearish_score": basic_bearish,
                "large_patterns_score": large_bullish_score,
                "current_patterns": pattern_results.get('current_patterns', []),
                "pattern_summary": f"{basic_bullish}B/{basic_bearish}Be + {large_bullish_score//2}L"
            },
            
            # Market Context & Sector
            "market_context": market_context,
            "sector_analysis": sector_analysis,
            
            # Combined Analysis
            "combined_analysis": {
                "base_score": base_score,
                "market_adjustment": market_adjustment,
                "sector_adjustment": sector_adjustment,
                "total_score": round(combined_score, 2),
                "final_recommendation": recommendation
            },
            
            # News Search Context for ChatGPT
            "news_search_context": news_context,
            
            # Technical Levels
            "technical_levels": {
                "support_level": round(float(latest['support_level']), 2) if pd.notna(latest['support_level']) else None,
                "resistance_level": round(float(latest['resistance_level']), 2) if pd.notna(latest['resistance_level']) else None,
                "EMA10": round(float(latest['EMA10']), 2) if pd.notna(latest['EMA10']) else None,
                "EMA20": round(float(latest['EMA20']), 2) if pd.notna(latest['EMA20']) else None
            },
            
            # System Info
            "system_info": {
                "version": "GTI Pro v2.0",
                "scoring_range": "-5 to +18 points",
                "enhanced_features": ["Large Patterns", "Market Context", "Sector Analysis", "News Integration"]
            }
        }
        
        print("‚úÖ HO√ÄN TH√ÄNH PH√ÇN T√çCH GTI PRO v2.0!")
        print(f"üìä K·∫æT QU·∫¢: {combined_score:.1f} ƒëi·ªÉm - {recommendation['emoji']} {recommendation['level']}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå L·ªñI PH√ÇN T√çCH: {e}")
        return {
            "status": "error",
            "message": f"L·ªói ph√¢n t√≠ch {stock_symbol}: {str(e)}"
        }

# ƒêo·∫°n m√£ ƒë·ªÉ ch·∫°y th·ª≠
if __name__ == "__main__":
    ma_can_kiem_tra = "FPT"
    
    print("üöÄ CH·∫†Y TH·ª¨ COMPREHENSIVE GTI ANALYSIS v2.0")
    print("="*50)
    
    # Test comprehensive analysis
    ket_qua_comprehensive = comprehensive_gti_analysis(ma_can_kiem_tra)
    
    if ket_qua_comprehensive['status'] == 'success':
        print(f"\nüìä K·∫æT QU·∫¢ COMPREHENSIVE CHO {ma_can_kiem_tra}:")
        print(f"GTI Score: {ket_qua_comprehensive['gti_analysis']['gti_score']}/4")
        print(f"Pattern Score: {ket_qua_comprehensive['pattern_analysis']['pattern_summary']}")
        print(f"Combined Score: {ket_qua_comprehensive['combined_analysis']['total_score']}")
        print(f"Recommendation: {ket_qua_comprehensive['combined_analysis']['final_recommendation']['emoji']} {ket_qua_comprehensive['combined_analysis']['final_recommendation']['level']}")
        
        print(f"\nüì∞ NEWS SEARCH CONTEXT:")
        print(ket_qua_comprehensive['news_search_context']['search_instruction'])
    else:
        print(f"‚ùå L·ªói: {ket_qua_comprehensive['message']}")
        
        # Fallback to old method
        print("\nüîÑ Ch·∫°y ph√¢n t√≠ch c≈©...")
        du_lieu = lay_du_lieu_co_phieu_vnstock(
            ma_co_phieu=ma_can_kiem_tra,
            start_date="2024-01-01",
            end_date="2025-06-28"
        )

        if du_lieu is not None:
            print(f"ƒê√£ l·∫•y ƒë∆∞·ª£c {len(du_lieu)} b·∫£n ghi cho m√£ {ma_can_kiem_tra}.")
            
            du_lieu_phan_tich = tinh_toan_chi_bao_ky_thuat(du_lieu)
            latest = du_lieu_phan_tich.iloc[-1]
            print(f"\nK·∫øt qu·∫£ c∆° b·∫£n:")
            print(f"Gi√° ƒë√≥ng c·ª≠a: {latest['close']:,.0f} VND")
            print(f"GTI Score: {latest['gti_score']}/4")
            print(f"GTI Signal: {latest['gti_signal']}")
        else:
            print("Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu. Vui l√≤ng:")
            print("1. Ki·ªÉm tra k·∫øt n·ªëi internet")
            print("2. C√†i ƒë·∫∑t vnstock: pip install vnstock")
            print("3. C√†i ƒë·∫∑t ta: pip install ta")
            print("4. Th·ª≠ l·∫°i v·ªõi m√£ c·ªï phi·∫øu kh√°c")