# main_api.py

import pandas as pd
from fastapi import FastAPI, HTTPException
from datetime import datetime, timedelta
from typing import Optional

# Import c√°c h√†m t·ª´ file lay_data_stock.py
from lay_data_stock import (
    lay_du_lieu_co_phieu_vnstock, 
    tinh_toan_chi_bao_ky_thuat,
    detect_free_patterns,
    detect_large_chart_patterns,
    phan_tich_pattern_results,
    get_market_context,
    get_sector_analysis,
    comprehensive_gti_analysis,
    prepare_news_search_context
)

# Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI
app = FastAPI(
    title="üöÄ GTI Stock Analysis API",
    description="API ph√¢n t√≠ch ch·ª©ng kho√°n Vi·ªát Nam v·ªõi h·ªá th·ªëng GTI (Growth Trading Intelligence) + Pattern Detection mi·ªÖn ph√≠",
    version="3.0.0",
    contact={
        "name": "GTI Analysis System",
        "url": "https://github.com/your-username/stock-gti-analysis",
    },
)

@app.get("/")
def read_root():
    return {
        "message": "üöÄ Ch√†o m·ª´ng ƒë·∫øn v·ªõi GTI Stock Analysis API!",
        "he_thong": "GTI PRO v2.0 - Growth Trading Intelligence + Enhanced Pattern Detection",
        "phien_ban": "3.2.0",
        "tinh_nang": [
            "üî• GTI Core Analysis (4 ti√™u ch√≠ c·ªët l√µi)",
            "üéØ Enhanced Pattern Detection (16 patterns: 12 basic + 4 large)",
            "üåä Market Context Analysis (VNINDEX + Sector)",
            "üì∞ News Search Integration (cho ChatGPT)",
            "‚ö° Combined Scoring (-5 to +18 range)",
            "üöÄ Comprehensive Analysis API"
        ],
        "endpoints": {
            "/phan-tich/{ma_co_phieu}": "Ph√¢n t√≠ch GTI c∆° b·∫£n",
            "/full-analysis/{ma_co_phieu}": "üöÄ GTI PRO v2.0 - Ph√¢n t√≠ch to√†n di·ªán",
            "/full-analysis-legacy/{ma_co_phieu}": "Ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß GTI + Patterns (legacy)",
            "/news-context/{ma_co_phieu}": "News search context cho ChatGPT",
            "/gti-info": "Th√¥ng tin v·ªÅ h·ªá th·ªëng GTI",
            "/patterns-info": "Th√¥ng tin v·ªÅ 16 patterns (12 basic + 4 large)"
        },
        "vi_du": "/full-analysis/FPT"
    }

@app.get("/phan-tich/{ma_co_phieu}")
def phan_tich_co_phieu(ma_co_phieu: str):
    """
    Endpoint ph√¢n t√≠ch GTI c∆° b·∫£n cho m·ªôt m√£ c·ªï phi·∫øu.
    
    Returns:
        Ph√¢n t√≠ch GTI v·ªõi ƒëi·ªÉm s·ªë 0-4 v√† t√≠n hi·ªáu BUY/HOLD/AVOID
    """
    # T√≠nh to√°n th·ªùi gian l·∫•y d·ªØ li·ªáu (1 nƒÉm t·ª´ hi·ªán t·∫°i)
    end_date = datetime.now().strftime("%Y-%m-%d")
    start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
    
    # L·∫•y d·ªØ li·ªáu
    df = lay_du_lieu_co_phieu_vnstock(
        ma_co_phieu=ma_co_phieu.upper(),
        start_date=start_date,
        end_date=end_date
    )
    
    if df is None or df.empty:
        raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho m√£: {ma_co_phieu}")
    
    # T√≠nh to√°n ch·ªâ b√°o GTI
    df_analyzed = tinh_toan_chi_bao_ky_thuat(df)
    
    # L·∫•y k·∫øt qu·∫£ c·ªßa ng√†y giao d·ªãch g·∫ßn nh·∫•t
    latest = df_analyzed.iloc[-1]
    
    # Chu·∫©n b·ªã k·∫øt qu·∫£ tr·∫£ v·ªÅ theo format GTI
    result = {
        # Th√¥ng tin c∆° b·∫£n
        "ma_co_phieu": ma_co_phieu.upper(),
        "ngay_cap_nhat": latest.name.strftime("%Y-%m-%d") if hasattr(latest.name, 'strftime') else str(latest.name),
        "gia_dong_cua": round(float(latest['close']), 2),
        "gia_cao_nhat": round(float(latest['high']), 2),
        "gia_thap_nhat": round(float(latest['low']), 2),
        "khoi_luong": int(latest['volume']) if pd.notna(latest['volume']) else 0,
        
        # C√°c ƒë∆∞·ªùng EMA theo GTI
        "EMA10": round(float(latest['EMA10']), 2) if pd.notna(latest['EMA10']) else None,
        "EMA20": round(float(latest['EMA20']), 2) if pd.notna(latest['EMA20']) else None,
        "EMA50": round(float(latest['EMA50']), 2) if pd.notna(latest['EMA50']) else None,
        "EMA200": round(float(latest['EMA200']), 2) if pd.notna(latest['EMA200']) else None,
        
        # C√°c ch·ªâ s·ªë GTI ch√≠nh
        "gti_trend_check": bool(latest['gti_trend_check']) if pd.notna(latest['gti_trend_check']) else False,
        "gti_recent_breakout": bool(latest['gti_recent_breakout']) if pd.notna(latest['gti_recent_breakout']) else False,
        "gti_dist_to_high_percent": round(float(latest['gti_dist_to_high_percent']), 2) if pd.notna(latest['gti_dist_to_high_percent']) else None,
        "gti_is_pullback": bool(latest['gti_is_pullback']) if pd.notna(latest['gti_is_pullback']) else False,
        
        # T·ªïng k·∫øt GTI
        "gti_score": int(latest['gti_score']) if pd.notna(latest['gti_score']) else 0,
        "gti_signal": str(latest['gti_signal']) if pd.notna(latest['gti_signal']) else "HOLD",
        
        # Metadata
        "he_thong": "GTI - Growth Trading Intelligence",
        "phien_ban": "3.0.0",
        "ghi_chu": "Ph√¢n t√≠ch GTI c∆° b·∫£n. S·ª≠ d·ª•ng /full-analysis/{ma_co_phieu} ƒë·ªÉ c√≥ pattern detection."
    }

    return result

@app.get("/full-analysis/{ma_co_phieu}")
def full_analysis_co_phieu(ma_co_phieu: str):
    """
    üöÄ Endpoint ph√¢n t√≠ch GTI PRO v2.0 TO√ÄN DI·ªÜN
    
    Includes:
    - GTI Core (4 ti√™u ch√≠) + Enhanced Patterns (16 patterns)
    - Market Context (VNINDEX) + Sector Analysis  
    - News Search Context cho ChatGPT
    - Combined Scoring (-5 to +18 range)
    """
    try:
        # S·ª≠ d·ª•ng comprehensive analysis function m·ªõi
        result = comprehensive_gti_analysis(ma_co_phieu.upper())
        
        if result['status'] == 'error':
            raise HTTPException(status_code=404, detail=result['message'])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói ph√¢n t√≠ch comprehensive cho {ma_co_phieu}: {str(e)}")

@app.get("/full-analysis-legacy/{ma_co_phieu}")
def full_analysis_legacy(ma_co_phieu: str):
    """
    üî• Endpoint ph√¢n t√≠ch ƒê·∫¶Y ƒê·ª¶ GTI + Pattern Detection (Legacy version)
    
    Returns:
        Ph√¢n t√≠ch t·ªïng h·ª£p GTI + 12 patterns mi·ªÖn ph√≠ + ƒëi·ªÉm t·ªïng h·ª£p
    """
    try:
        # T√≠nh to√°n th·ªùi gian l·∫•y d·ªØ li·ªáu (1 nƒÉm t·ª´ hi·ªán t·∫°i)
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        # L·∫•y d·ªØ li·ªáu
        df = lay_du_lieu_co_phieu_vnstock(
            ma_co_phieu=ma_co_phieu.upper(),
            start_date=start_date,
            end_date=end_date
        )
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho m√£: {ma_co_phieu}")
        
        # T√≠nh to√°n ch·ªâ b√°o GTI
        df_analyzed = tinh_toan_chi_bao_ky_thuat(df)
        
        # Ph√°t hi·ªán patterns mi·ªÖn ph√≠
        df_patterns = detect_free_patterns(df_analyzed)
        
        # üî• TH√äM: Ph√°t hi·ªán large chart patterns
        df_patterns = detect_large_chart_patterns(df_patterns)
        
        # Ph√¢n t√≠ch k·∫øt qu·∫£ patterns
        pattern_results = phan_tich_pattern_results(df_patterns, ma_co_phieu.upper())
        
        # üåä TH√äM: L·∫•y b·ªëi c·∫£nh th·ªã tr∆∞·ªùng v√† ng√†nh
        market_context = get_market_context()
        sector_analysis = get_sector_analysis(ma_co_phieu.upper())
        
        # L·∫•y k·∫øt qu·∫£ c·ªßa ng√†y giao d·ªãch g·∫ßn nh·∫•t
        latest = df_patterns.iloc[-1]
        
        # Safe date formatting
        try:
            if hasattr(latest.name, 'strftime'):
                ngay_cap_nhat = latest.name.strftime("%Y-%m-%d")
            else:
                ngay_cap_nhat = str(latest.name)
        except:
            ngay_cap_nhat = datetime.now().strftime("%Y-%m-%d")
        
        # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p
        gti_score = int(latest['gti_score']) if pd.notna(latest['gti_score']) else 0
        bullish_score = int(pattern_results.get('bullish_score', 0))
        bearish_score = int(pattern_results.get('bearish_score', 0))
        tong_diem = gti_score + bullish_score - bearish_score
        
        # ƒê√°nh gi√° t·ªïng h·ª£p
        if tong_diem >= 4:
            danh_gia = "üü¢ R·∫§T T√çCH C·ª∞C - C√ÇN NH·∫ÆC MUA"
            mau_sac = "green"
        elif tong_diem >= 2:
            danh_gia = "üü° T√çCH C·ª∞C - THEO D√ïI"
            mau_sac = "yellow"
        elif tong_diem >= 0:
            danh_gia = "üü† TRUNG T√çNH - CH·ªú T√çN HI·ªÜU"
            mau_sac = "orange"
        else:
            danh_gia = "üî¥ TI√äU C·ª∞C - TR√ÅNH XA"
            mau_sac = "red"
        
        # Chu·∫©n b·ªã k·∫øt qu·∫£ tr·∫£ v·ªÅ
        result = {
            # Th√¥ng tin c∆° b·∫£n
            "ma_co_phieu": ma_co_phieu.upper(),
            "ngay_cap_nhat": ngay_cap_nhat,
            "gia_dong_cua": round(float(latest['close']), 2),
            "khoi_luong": int(latest['volume']) if pd.notna(latest['volume']) else 0,
            
            # GTI Analysis
            "gti_analysis": {
                "gti_trend_check": bool(latest['gti_trend_check']) if pd.notna(latest['gti_trend_check']) else False,
                "gti_recent_breakout": bool(latest['gti_recent_breakout']) if pd.notna(latest['gti_recent_breakout']) else False,
                "gti_dist_to_high_percent": round(float(latest['gti_dist_to_high_percent']), 2) if pd.notna(latest['gti_dist_to_high_percent']) else None,
                "gti_is_pullback": bool(latest['gti_is_pullback']) if pd.notna(latest['gti_is_pullback']) else False,
                "gti_score": gti_score,
                "gti_signal": str(latest['gti_signal']) if pd.notna(latest['gti_signal']) else "HOLD"
            },
            
            # Pattern Analysis
            "pattern_analysis": {
                "bullish_score": bullish_score,
                "bearish_score": bearish_score,
                "current_patterns": pattern_results.get('current_patterns', []),
                "pattern_summary": f"{bullish_score}B/{bearish_score}Be"
            },
            
            # K·∫øt h·ª£p GTI + Patterns
            "combined_analysis": {
                "tong_diem": tong_diem,
                "danh_gia": danh_gia,
                "mau_sac": mau_sac,
                "chi_tiet": f"GTI: {gti_score}/4 + Pattern: {bullish_score}B/{bearish_score}Be"
            },
            
            # Support/Resistance Levels
            "levels": {
                "support_level": round(float(latest['support_level']), 2) if pd.notna(latest['support_level']) else None,
                "resistance_level": round(float(latest['resistance_level']), 2) if pd.notna(latest['resistance_level']) else None,
                "EMA10": round(float(latest['EMA10']), 2) if pd.notna(latest['EMA10']) else None,
                "EMA20": round(float(latest['EMA20']), 2) if pd.notna(latest['EMA20']) else None
            },
            
            # üåä Market Context & Sector Analysis
            "market_context": market_context,
            "sector_analysis": sector_analysis,
            
            # Metadata
            "he_thong": "GTI + Pattern Detection + Market Context",
            "phien_ban": "3.1.0",
            "timestamp": datetime.now().isoformat()
        }

        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω d·ªØ li·ªáu cho {ma_co_phieu}: {str(e)}")

@app.get("/news-context/{ma_co_phieu}")
def get_news_context(ma_co_phieu: str):
    """
    üì∞ Endpoint cho ChatGPT l·∫•y news search context
    
    Returns:
        Context v√† h∆∞·ªõng d·∫´n search tin t·ª©c cho ChatGPT
    """
    try:
        # L·∫•y th√¥ng tin ng√†nh
        sector_analysis = get_sector_analysis(ma_co_phieu.upper())
        sector_name = sector_analysis.get('sector_name') if sector_analysis.get('status') == 'success' else None
        
        # T·∫°o news search context
        news_context = prepare_news_search_context(ma_co_phieu.upper(), sector_name)
        
        return {
            "stock_symbol": ma_co_phieu.upper(),
            "sector_info": {
                "sector_name": sector_name,
                "status": sector_analysis.get('status', 'unknown')
            },
            "news_search_context": news_context,
            "important_note": "üìä T·∫•t c·∫£ d·ªØ li·ªáu v·ªÅ gi√°, volume, ch·ªâ s·ªë k·ªπ thu·∫≠t ƒë√£ ƒë∆∞·ª£c cung c·∫•p qua API - CH·ªà search tin t·ª©c v√† s·ª± ki·ªán!"
        }
        
    except Exception as e:
        return {
            "error": f"L·ªói t·∫°o news context cho {ma_co_phieu}: {str(e)}",
            "fallback_context": prepare_news_search_context(ma_co_phieu.upper(), None)
        }

@app.get("/patterns-info")
def patterns_info():
    """
    Th√¥ng tin v·ªÅ 16 patterns ƒë∆∞·ª£c s·ª≠ d·ª•ng (12 basic + 4 large)
    """
    return {
        "title": "üéØ 16 Chart Patterns Detection",
        "version": "Enhanced v2.0",
        "basic_patterns": {
            "candlestick_patterns": [
                {"name": "Doji", "description": "N·∫øn doji - bi·ªÉu hi·ªán s·ª± do d·ª± c·ªßa th·ªã tr∆∞·ªùng", "points": 0},
                {"name": "Hammer", "description": "N·∫øn b√∫a - t√≠n hi·ªáu ƒë·∫£o chi·ªÅu tƒÉng", "points": "+1"},
                {"name": "Hanging Man", "description": "N·∫øn treo c·ªï - t√≠n hi·ªáu ƒë·∫£o chi·ªÅu gi·∫£m", "points": "-1"}
            ],
            "engulfing_patterns": [
                {"name": "Bullish Engulfing", "description": "N·∫øn bao ph·ªß tƒÉng - t√≠n hi·ªáu m·∫°nh", "points": "+1"},
                {"name": "Bearish Engulfing", "description": "N·∫øn bao ph·ªß gi·∫£m - t√≠n hi·ªáu y·∫øu", "points": "-1"}
            ],
            "star_patterns": [
                {"name": "Morning Star", "description": "Sao mai - 3 n·∫øn ƒë·∫£o chi·ªÅu tƒÉng", "points": "+1"},
                {"name": "Evening Star", "description": "Sao h√¥m - 3 n·∫øn ƒë·∫£o chi·ªÅu gi·∫£m", "points": "-1"}
            ],
            "breakout_patterns": [
                {"name": "Resistance Breakout", "description": "V∆∞·ª£t kh√°ng c·ª± v·ªõi volume cao", "points": "+1"},
                {"name": "Support Breakdown", "description": "Th·ªßng h·ªó tr·ª£ v·ªõi volume cao", "points": "-1"}
            ],
            "volume_patterns": [
                {"name": "Volume Spike", "description": "Kh·ªëi l∆∞·ª£ng b·∫•t th∆∞·ªùng > 2x trung b√¨nh", "points": 0}
            ],
            "gap_patterns": [
                {"name": "Gap Up", "description": "Gap tƒÉng v·ªõi momentum", "points": "+1"},
                {"name": "Gap Down", "description": "Gap gi·∫£m v·ªõi momentum", "points": "-1"}
            ],
            "trend_patterns": [
                {"name": "Strong Uptrend", "description": "Xu h∆∞·ªõng tƒÉng m·∫°nh 5 ng√†y", "points": "+1"}
            ]
        },
        "large_patterns": {
            "description": "Large chart patterns (worth 2 points each)",
            "patterns": [
                {"name": "Cup & Handle", "description": "Cup & Handle - m·∫´u h√¨nh ch·ª©a s√¢u + tay c·∫ßm", "points": "+2"},
                {"name": "Bull Flag", "description": "Bull Flag - c·ªôt c·ªù + consolidation", "points": "+2"},
                {"name": "Base n' Break", "description": "Base n' Break - t√≠ch l≈©y + breakout", "points": "+2"},
                {"name": "Ascending Triangle", "description": "Ascending Triangle - support tƒÉng d·∫ßn", "points": "+2"}
            ]
        },
        "scoring_system": {
            "basic_bullish": ["bullish_engulfing", "morning_star", "hammer", "resistance_breakout", "gap_up", "strong_uptrend"],
            "basic_bearish": ["bearish_engulfing", "evening_star", "hanging_man", "support_breakdown", "gap_down"],
            "neutral_patterns": ["doji", "volume_spike"],
            "large_bullish": ["cup_handle", "bull_flag", "base_n_break", "ascending_triangle"],
            "scoring_formula": "GTI (0-4) + Basic Bullish (+1 each) - Basic Bearish (-1 each) + Large Patterns (+2 each) + Market Context Adjustments"
        },
        "total_range": "Score range: -5 to +18 points"
    }

@app.get("/custom-gpt-instructions")
def get_custom_gpt_instructions():
    """
    Endpoint ƒë·ªÉ Custom GPT ƒë·ªçc h∆∞·ªõng d·∫´n t·ª´ file custom_gpt.md
    """
    try:
        with open("custom_gpt.md", "r", encoding="utf-8") as f:
            content = f.read()
        return {
            "instructions": content,
            "usage": "ƒê√¢y l√† h∆∞·ªõng d·∫´n chi ti·∫øt ƒë·ªÉ t√≠ch h·ª£p API v·ªõi Custom GPT",
            "api_base_url": "S·ª≠ d·ª•ng URL hi·ªán t·∫°i c·ªßa server n√†y",
            "main_endpoints": [
                "/full-analysis/{ma_co_phieu}",
                "/phan-tich/{ma_co_phieu}",
                "/gti-info",
                "/patterns-info"
            ]
        }
    except FileNotFoundError:
        return {"error": "File custom_gpt.md kh√¥ng t·ªìn t·∫°i"}
    except Exception as e:
        return {"error": f"L·ªói ƒë·ªçc file: {str(e)}"}

@app.get("/test")
def test_endpoint():
    """Simple test endpoint"""
    return {"status": "OK", "message": "Test endpoint works!"}

@app.get("/test-data/{stock}")
def test_data_only(stock: str):
    """Test data fetching only"""
    try:
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        df = lay_du_lieu_co_phieu_vnstock(stock.upper(), start_date, end_date)
        
        if df is None or df.empty:
            return {"error": "No data", "stock": stock}
        
        return {
            "success": True,
            "stock": stock.upper(),
            "rows": len(df),
            "columns": len(df.columns),
            "last_close": float(df['close'].iloc[-1]),
            "columns_list": list(df.columns)[:5]
        }
    except Exception as e:
        return {"error": str(e), "type": type(e).__name__}

@app.get("/test-gti/{stock}")
def test_gti_only(stock: str):
    """Test GTI calculation only"""
    try:
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        # Step 1: Get data
        df = lay_du_lieu_co_phieu_vnstock(stock.upper(), start_date, end_date)
        if df is None or df.empty:
            return {"error": "No data", "step": 1}
        
        # Step 2: GTI calculation
        df_gti = tinh_toan_chi_bao_ky_thuat(df)
        latest = df_gti.iloc[-1]
        
        return {
            "success": True,
            "stock": stock.upper(),
            "gti_score": int(latest['gti_score']),
            "gti_signal": str(latest['gti_signal']),
            "gti_trend_check": bool(latest['gti_trend_check']),
            "gti_recent_breakout": bool(latest['gti_recent_breakout']),
            "price": float(latest['close'])
        }
    except Exception as e:
        return {"error": str(e), "type": type(e).__name__}

@app.get("/debug/{ma_co_phieu}")
def debug_analysis(ma_co_phieu: str):
    """
    Debug endpoint ƒë·ªÉ test t·ª´ng b∆∞·ªõc
    """
    try:
        # Step 1: Get data
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        
        df = lay_du_lieu_co_phieu_vnstock(ma_co_phieu.upper(), start_date, end_date)
        if df is None or df.empty:
            return {"error": "Kh√¥ng c√≥ d·ªØ li·ªáu", "step": 1}
        
        # Step 2: GTI calculation
        df_gti = tinh_toan_chi_bao_ky_thuat(df)
        
        # Step 3: Pattern detection
        df_patterns = detect_free_patterns(df_gti)
        
        # Step 4: Pattern results
        pattern_results = phan_tich_pattern_results(df_patterns, ma_co_phieu.upper())
        
        # Step 5: Latest data
        latest = df_patterns.iloc[-1]
        
        return {
            "success": True,
            "steps_completed": 5,
            "gti_score": int(latest['gti_score']),
            "bullish_score": pattern_results.get('bullish_score', 0),
            "bearish_score": pattern_results.get('bearish_score', 0),
            "pattern_results_keys": list(pattern_results.keys()) if pattern_results else [],
            "latest_columns": list(latest.index)[:10]  # First 10 columns
        }
        
    except Exception as e:
        return {"error": str(e), "type": str(type(e).__name__)}

@app.get("/gti-info")
def gti_info():
    """
    Th√¥ng tin chi ti·∫øt v·ªÅ h·ªá th·ªëng GTI
    """
    return {
        "ten_he_thong": "GTI - Growth Trading Intelligence", 
        "muc_tieu": {
            "thoi_gian_nam_giu": "T·ªëi ƒëa 1 th√°ng",
            "sinh_loi_muc_tieu": "10-25%",
            "cat_lo": "5-8%"
        },
        "tieu_chi_loc": [
            "‚úÖ Xu h∆∞·ªõng k·ªπ thu·∫≠t: EMA10 > EMA20 v√† gi√° n·∫±m tr√™n c·∫£ EMA10 & EMA20",
            "‚úÖ Volume & breakout: C√≥ √≠t nh·∫•t 1 phi√™n breakout v·ªõi volume > 1.5x TB20",
            "‚úÖ V·ªã tr√≠ gi√°: ∆Øu ti√™n c·ªï phi·∫øu ti·ªám c·∫≠n ƒë·ªânh 1 nƒÉm (< 15%)",
            "‚úÖ Pullback ƒë√∫ng chu·∫©n: Sau breakout, pullback v·ªÅ EMA10 ho·∫∑c EMA20"
        ],
        "bang_diem_gti": {
            "4_diem": "üü¢ R·∫§T T√çCH C·ª∞C - BUY signal",
            "3_diem": "üü° T√çCH C·ª∞C - Theo d√µi",
            "2_diem": "üü† TRUNG T√çNH - HOLD",
            "0-1_diem": "üî¥ TI√äU C·ª∞C - AVOID"
        },
        "chi_so_tra_ve": {
            "gti_trend_check": "Ki·ªÉm tra xu h∆∞·ªõng GTI (True/False)",
            "gti_recent_breakout": "C√≥ breakout g·∫ßn ƒë√¢y kh√¥ng (True/False)",
            "gti_dist_to_high_percent": "Kho·∫£ng c√°ch ƒë·∫øn ƒë·ªânh 1 nƒÉm (%)",
            "gti_is_pullback": "ƒêang pullback v·ªÅ EMA10/20 kh√¥ng (True/False)",
            "gti_score": "ƒêi·ªÉm t·ªïng GTI (0-4)",
            "gti_signal": "T√≠n hi·ªáu GTI (BUY/HOLD/AVOID)"
        }
    }